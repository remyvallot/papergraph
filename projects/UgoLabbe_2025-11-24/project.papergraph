{
  "edges": [
    {
      "id": 1,
      "to": 6,
      "from": 10,
      "label": ""
    },
    {
      "id": 3,
      "to": 27,
      "from": 31,
      "label": ""
    },
    {
      "id": 4,
      "to": 21,
      "from": 2,
      "label": ""
    },
    {
      "id": 5,
      "to": 3,
      "from": 21,
      "label": ""
    },
    {
      "id": 6,
      "to": 5,
      "from": 6,
      "label": ""
    },
    {
      "id": 7,
      "to": 22,
      "from": 12,
      "label": ""
    },
    {
      "id": 8,
      "to": 8,
      "from": 10,
      "label": ""
    },
    {
      "id": 9,
      "to": 31,
      "from": 10,
      "label": ""
    },
    {
      "id": 12,
      "to": 21,
      "from": 23,
      "label": ""
    },
    {
      "id": 13,
      "to": 31,
      "from": 16,
      "label": ""
    },
    {
      "id": 16,
      "to": 19,
      "from": 2,
      "label": ""
    },
    {
      "id": 17,
      "to": 31,
      "from": 20,
      "label": ""
    },
    {
      "id": 22,
      "to": 31,
      "from": 30,
      "label": ""
    },
    {
      "id": 23,
      "to": 28,
      "from": 21,
      "label": ""
    },
    {
      "id": 24,
      "to": 31,
      "from": 29,
      "label": ""
    },
    {
      "id": 25,
      "to": 31,
      "from": 23,
      "label": ""
    },
    {
      "id": 26,
      "to": 22,
      "from": 23,
      "label": ""
    },
    {
      "id": 27,
      "to": 21,
      "from": 36,
      "label": ""
    },
    {
      "id": 28,
      "to": 39,
      "from": 38,
      "label": ""
    },
    {
      "id": 29,
      "to": 40,
      "from": 38,
      "label": ""
    },
    {
      "id": 33,
      "to": 44,
      "from": 38,
      "label": ""
    },
    {
      "id": 34,
      "to": 45,
      "from": 31,
      "label": ""
    },
    {
      "id": 35,
      "to": 27,
      "from": 45,
      "label": ""
    },
    {
      "id": 36,
      "to": 46,
      "from": 38,
      "label": ""
    },
    {
      "id": 37,
      "to": 47,
      "from": 38,
      "label": ""
    },
    {
      "id": 38,
      "to": 48,
      "from": 49,
      "label": ""
    },
    {
      "id": 39,
      "to": 51,
      "from": 10,
      "label": ""
    },
    {
      "id": 40,
      "to": 53,
      "from": 54,
      "label": ""
    },
    {
      "id": 41,
      "to": 52,
      "from": 53,
      "label": ""
    }
  ],
  "nodes": [
    {
      "id": 1,
      "doi": "10.48550/arXiv.2304.05091",
      "pdf": "",
      "url": "http://arxiv.org/abs/2304.05091",
      "date": "2023-01-01",
      "isbn": "",
      "issn": "",
      "link": "http://arxiv.org/abs/2304.05091",
      "note": "arXiv:2304.05091",
      "text": "Gaussian processes (GPs) are typically criticised for their unfavourable scaling in both computational and memory requirements. For large datasets, sparse GPs reduce these demands by conditioning on a small set of inducing variables designed to summarise the data. In practice however, for large datasets requiring many inducing variables, such as low-lengthscale spatial data, even sparse GPs can become computationally expensive, limited by the number of inducing variables one can use. In this work, we propose a new class of inter-domain variational GP, constructed by projecting a GP onto a set of compactly supported B-spline basis functions. The key benefit of our approach is that the compact support of the B-spline basis functions admits the use of sparse linear algebra to significantly speed up matrix operations and drastically reduce the memory footprint. This allows us to very efficiently model fast-varying spatial phenomena with tens of thousands of inducing variables, where previous approaches failed.",
      "year": "2023",
      "month": "",
      "pages": "",
      "title": "Actually {Sparse",
      "number": "",
      "school": "",
      "series": "",
      "volume": "",
      "address": "",
      "authors": "Cunningham, Harry Jake and Souza, Daniel Augusto de and Takao, So and Wilk, Mark van der and Deisenroth, Marc Peter",
      "chapter": "",
      "edition": "",
      "journal": "",
      "abstract": "Gaussian processes (GPs) are typically criticised for their unfavourable scaling in both computational and memory requirements. For large datasets, sparse GPs reduce these demands by conditioning on a small set of inducing variables designed to summarise the data. In practice however, for large datasets requiring many inducing variables, such as low-lengthscale spatial data, even sparse GPs can become computationally expensive, limited by the number of inducing variables one can use. In this work, we propose a new class of inter-domain variational GP, constructed by projecting a GP onto a set of compactly supported B-spline basis functions. The key benefit of our approach is that the compact support of the B-spline basis functions admits the use of sparse linear algebra to significantly speed up matrix operations and drastically reduce the memory footprint. This allows us to very efficiently model fast-varying spatial phenomena with tens of thousands of inducing variables, where previous approaches failed.",
      "bibtexId": "cunningham_actually_2023",
      "keywords": "Computer Science - Machine Learning, Statistics - Machine Learning",
      "booktitle": "",
      "entryType": "misc",
      "publisher": "arXiv",
      "categories": [
        "Other GP Litterature"
      ],
      "citationKey": "cunningham_actually_2023",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@misc{cunningham_actually_2023, \ttitle = {Actually {Sparse} {Variational} {Gaussian} {Processes}}, \turl = {http://arxiv.org/abs/2304.05091}, \tdoi = {10.48550/arXiv.2304.05091}, \tabstract = {Gaussian processes (GPs) are typically criticised for their unfavourable scaling in both computational and memory requirements. For large datasets, sparse GPs reduce these demands by conditioning on a small set of inducing variables designed to summarise the data. In practice however, for large datasets requiring many inducing variables, such as low-lengthscale spatial data, even sparse GPs can become computationally expensive, limited by the number of inducing variables one can use. In this work, we propose a new class of inter-domain variational GP, constructed by projecting a GP onto a set of compactly supported B-spline basis functions. The key benefit of our approach is that the compact support of the B-spline basis functions admits the use of sparse linear algebra to significantly speed up matrix operations and drastically reduce the memory footprint. This allows us to very efficiently model fast-varying spatial phenomena with tens of thousands of inducing variables, where previous approaches failed.}, \turldate = {2025-10-14}, \tpublisher = {arXiv}, \tauthor = {Cunningham, Harry Jake and Souza, Daniel Augusto de and Takao, So and Wilk, Mark van der and Deisenroth, Marc Peter}, \tmonth = apr, \tyear = {2023}, \tnote = {arXiv:2304.05091}, \tkeywords = {Computer Science - Machine Learning, Statistics - Machine Learning}, }"
    },
    {
      "id": 2,
      "doi": "",
      "pdf": "",
      "url": "https://hal.science/tel-03276426",
      "date": "2021-01-01",
      "isbn": "",
      "issn": "",
      "link": "https://hal.science/tel-03276426",
      "note": "",
      "text": "In engineering, the design of complex systems, such as aerospace launch vehicles, involves the analysis and optimization of problems presenting diverse challenges. Actually, the designer has to ake into account different aspects in the design of complex systems, such as the presence of black-box computationally expensive functions, the complex behavior of the optimized performance (e.g., abrupt change of a physical property here referred as nonstationarity), the multiple objectives and constraints involved, the multi-source information handling in a multi-fidelity framework, and the epistemic and aleatory uncertainties affecting the physical models. A wide range of machine learning methods are used to address these various challenges. Among these approaches, Gaussian Processes (GPs), benefiting from their Bayesian and non-parametric formulation, are popular in the literature and diverse state-of-the-art algorithms for the design of complex systems are based on these models. Despite being widely used for the analysis and optimization of complex systems, GPs, still present some limitations. For the optimization of computationally expensive functions, GPs are used within the Bayesian optimization framework as regression models. However, for the optimization of non-stationary problems, they are not suitable due to the use of a prior stationary covariance function. Furthermore, in Bayesian optimization of multiple objectives, a GP is used for each involved objective independently, which prevents the exhibition of a potential correlation between the objectives. Another limitation occurs in multi-fidelity analysis where GP-based models are used to improve high-fidelity models using low-fidelity information. However, these models usually assume that the different fidelity input spaces are identically defined, which is not the case in some design problems. In this thesis, approaches are developed to overcome the limits of GPs in the analysis and optimization of complex systems. These approaches are based on Deep Gaussian Processes (DGPs), the hierarchical generalization of Gaussian processes. To handle non-stationarity in Bayesian optimization, a framework is developed that couples Bayesian optimization with DGPs. The inner layers allow a non-parametric Bayesian mapping of the input space to better represent non-stationary functions. For multi-objective Bayesian optimization, a multi-objective DGP model is developed. Each layer of this model corresponds to an objective and the different layers are connected with undirected edges to encode the potential correlation between objectives. Moreover, a computational approach for the expected hyper-volume improvement is proposed to take into account this correlation at the infill criterion level as well. Finally, to address multi-fidelity analysis for different input space definitions, a two-level DGP model is developed. This model allows a joint optimization of the multi-fidelity model and the input space mapping between fidelities. The different approaches developed are assessed on analytical problems as well as on representative aerospace vehicle design problems with respect to state-of-the-art approaches.",
      "year": "2021",
      "month": "",
      "pages": "",
      "title": "Deep {Gaussian",
      "number": "",
      "school": "Université de Lille",
      "series": "",
      "volume": "",
      "address": "",
      "authors": "Hebbal, Ali",
      "chapter": "",
      "edition": "",
      "journal": "",
      "abstract": "In engineering, the design of complex systems, such as aerospace launch vehicles, involves the analysis and optimization of problems presenting diverse challenges. Actually, the designer has to ake into account different aspects in the design of complex systems, such as the presence of black-box computationally expensive functions, the complex behavior of the optimized performance (e.g., abrupt change of a physical property here referred as nonstationarity), the multiple objectives and constraints involved, the multi-source information handling in a multi-fidelity framework, and the epistemic and aleatory uncertainties affecting the physical models. A wide range of machine learning methods are used to address these various challenges. Among these approaches, Gaussian Processes (GPs), benefiting from their Bayesian and non-parametric formulation, are popular in the literature and diverse state-of-the-art algorithms for the design of complex systems are based on these models. Despite being widely used for the analysis and optimization of complex systems, GPs, still present some limitations. For the optimization of computationally expensive functions, GPs are used within the Bayesian optimization framework as regression models. However, for the optimization of non-stationary problems, they are not suitable due to the use of a prior stationary covariance function. Furthermore, in Bayesian optimization of multiple objectives, a GP is used for each involved objective independently, which prevents the exhibition of a potential correlation between the objectives. Another limitation occurs in multi-fidelity analysis where GP-based models are used to improve high-fidelity models using low-fidelity information. However, these models usually assume that the different fidelity input spaces are identically defined, which is not the case in some design problems. In this thesis, approaches are developed to overcome the limits of GPs in the analysis and optimization of complex systems. These approaches are based on Deep Gaussian Processes (DGPs), the hierarchical generalization of Gaussian processes. To handle non-stationarity in Bayesian optimization, a framework is developed that couples Bayesian optimization with DGPs. The inner layers allow a non-parametric Bayesian mapping of the input space to better represent non-stationary functions. For multi-objective Bayesian optimization, a multi-objective DGP model is developed. Each layer of this model corresponds to an objective and the different layers are connected with undirected edges to encode the potential correlation between objectives. Moreover, a computational approach for the expected hyper-volume improvement is proposed to take into account this correlation at the infill criterion level as well. Finally, to address multi-fidelity analysis for different input space definitions, a two-level DGP model is developed. This model allows a joint optimization of the multi-fidelity model and the input space mapping between fidelities. The different approaches developed are assessed on analytical problems as well as on representative aerospace vehicle design problems with respect to state-of-the-art approaches.",
      "bibtexId": "hebbal_deep_2021",
      "keywords": "",
      "booktitle": "",
      "entryType": "phdthesis",
      "publisher": "",
      "categories": [
        "MF-DGP",
        "MF-GP"
      ],
      "citationKey": "hebbal_deep_2021",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@phdthesis{hebbal_deep_2021, \ttype = {phdthesis}, \ttitle = {Deep {Gaussian} {Processes} for the {Analysis} and {Optimization} of {Complex} {Systems} -{Application} to {Aerospace} {System} {Design}}, \turl = {https://hal.science/tel-03276426}, \tabstract = {In engineering, the design of complex systems, such as aerospace launch vehicles, involves the analysis and optimization of problems presenting diverse challenges. Actually, the designer has to ake into account different aspects in the design of complex systems, such as the presence of black-box computationally expensive functions, the complex behavior of the optimized performance (e.g., abrupt change of a physical property here referred as nonstationarity), the multiple objectives and constraints involved, the multi-source information handling in a multi-fidelity framework, and the epistemic and aleatory uncertainties affecting the physical models. A wide range of machine learning methods are used to address these various challenges. Among these approaches, Gaussian Processes (GPs), benefiting from their Bayesian and non-parametric formulation, are popular in the literature and diverse state-of-the-art algorithms for the design of complex systems are based on these models. Despite being widely used for the analysis and optimization of complex systems, GPs, still present some limitations. For the optimization of computationally expensive functions, GPs are used within the Bayesian optimization framework as regression models. However, for the optimization of non-stationary problems, they are not suitable due to the use of a prior stationary covariance function. Furthermore, in Bayesian optimization of multiple objectives, a GP is used for each involved objective independently, which prevents the exhibition of a potential correlation between the objectives. Another limitation occurs in multi-fidelity analysis where GP-based models are used to improve high-fidelity models using low-fidelity information. However, these models usually assume that the different fidelity input spaces are identically defined, which is not the case in some design problems. In this thesis, approaches are developed to overcome the limits of GPs in the analysis and optimization of complex systems. These approaches are based on Deep Gaussian Processes (DGPs), the hierarchical generalization of Gaussian processes. To handle non-stationarity in Bayesian optimization, a framework is developed that couples Bayesian optimization with DGPs. The inner layers allow a non-parametric Bayesian mapping of the input space to better represent non-stationary functions. For multi-objective Bayesian optimization, a multi-objective DGP model is developed. Each layer of this model corresponds to an objective and the different layers are connected with undirected edges to encode the potential correlation between objectives. Moreover, a computational approach for the expected hyper-volume improvement is proposed to take into account this correlation at the infill criterion level as well. Finally, to address multi-fidelity analysis for different input space definitions, a two-level DGP model is developed. This model allows a joint optimization of the multi-fidelity model and the input space mapping between fidelities. The different approaches developed are assessed on analytical problems as well as on representative aerospace vehicle design problems with respect to state-of-the-art approaches.}, \tlanguage = {en}, \turldate = {2025-10-14}, \tschool = {Université de Lille}, \tauthor = {Hebbal, Ali}, \tmonth = jan, \tyear = {2021}, }"
    },
    {
      "id": 3,
      "doi": "10.48550/arXiv.1705.08933",
      "pdf": "",
      "url": "http://arxiv.org/abs/1705.08933",
      "date": "2017-01-01",
      "isbn": "",
      "issn": "",
      "link": "http://arxiv.org/abs/1705.08933",
      "note": "arXiv:1705.08933",
      "text": "Gaussian processes (GPs) are a good choice for function approximation as they are flexible, robust to over-fitting, and provide well-calibrated predictive uncertainty. Deep Gaussian processes (DGPs) are multi-layer generalisations of GPs, but inference in these models has proved challenging. Existing approaches to inference in DGP models assume approximate posteriors that force independence between the layers, and do not work well in practice. We present a doubly stochastic variational inference algorithm, which does not force independence between layers. With our method of inference we demonstrate that a DGP model can be used effectively on data ranging in size from hundreds to a billion points. We provide strong empirical evidence that our inference scheme for DGPs works well in practice in both classification and regression.",
      "year": "2017",
      "month": "",
      "pages": "",
      "title": "Doubly {Stochastic",
      "number": "",
      "school": "",
      "series": "",
      "volume": "",
      "address": "",
      "authors": "Salimbeni, Hugh and Deisenroth, Marc",
      "chapter": "",
      "edition": "",
      "journal": "",
      "abstract": "Gaussian processes (GPs) are a good choice for function approximation as they are flexible, robust to over-fitting, and provide well-calibrated predictive uncertainty. Deep Gaussian processes (DGPs) are multi-layer generalisations of GPs, but inference in these models has proved challenging. Existing approaches to inference in DGP models assume approximate posteriors that force independence between the layers, and do not work well in practice. We present a doubly stochastic variational inference algorithm, which does not force independence between layers. With our method of inference we demonstrate that a DGP model can be used effectively on data ranging in size from hundreds to a billion points. We provide strong empirical evidence that our inference scheme for DGPs works well in practice in both classification and regression.",
      "bibtexId": "salimbeni_doubly_2017",
      "keywords": "Statistics - Machine Learning",
      "booktitle": "",
      "entryType": "misc",
      "publisher": "arXiv",
      "categories": [
        "Other GP Litterature"
      ],
      "citationKey": "salimbeni_doubly_2017",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@misc{salimbeni_doubly_2017, \ttitle = {Doubly {Stochastic} {Variational} {Inference} for {Deep} {Gaussian} {Processes}}, \turl = {http://arxiv.org/abs/1705.08933}, \tdoi = {10.48550/arXiv.1705.08933}, \tabstract = {Gaussian processes (GPs) are a good choice for function approximation as they are flexible, robust to over-fitting, and provide well-calibrated predictive uncertainty. Deep Gaussian processes (DGPs) are multi-layer generalisations of GPs, but inference in these models has proved challenging. Existing approaches to inference in DGP models assume approximate posteriors that force independence between the layers, and do not work well in practice. We present a doubly stochastic variational inference algorithm, which does not force independence between layers. With our method of inference we demonstrate that a DGP model can be used effectively on data ranging in size from hundreds to a billion points. We provide strong empirical evidence that our inference scheme for DGPs works well in practice in both classification and regression.}, \turldate = {2025-10-10}, \tpublisher = {arXiv}, \tauthor = {Salimbeni, Hugh and Deisenroth, Marc}, \tmonth = nov, \tyear = {2017}, \tnote = {arXiv:1705.08933}, \tkeywords = {Statistics - Machine Learning}, }"
    },
    {
      "id": 4,
      "doi": "10.1016/j.compchemeng.2023.108194",
      "pdf": "",
      "url": "https://linkinghub.elsevier.com/retrieve/pii/S0098135423000637",
      "date": "2023-01-01",
      "isbn": "",
      "issn": "00981354",
      "link": "https://linkinghub.elsevier.com/retrieve/pii/S0098135423000637",
      "note": "",
      "text": "",
      "year": "2023",
      "month": "",
      "pages": "108194",
      "title": "Combining multi-fidelity modelling and asynchronous batch {Bayesian",
      "number": "",
      "school": "",
      "series": "",
      "volume": "172",
      "address": "",
      "authors": "Folch, Jose Pablo and Lee, Robert M. and Shafei, Behrang and Walz, David and Tsay, Calvin and Van Der Wilk, Mark and Misener, Ruth",
      "chapter": "",
      "edition": "",
      "journal": "Computers \\& Chemical Engineering",
      "abstract": "",
      "bibtexId": "folch_combining_2023",
      "keywords": "",
      "booktitle": "",
      "entryType": "article",
      "publisher": "",
      "categories": [
        "BO-GP",
        "MF-GP",
        "Application MF-GP"
      ],
      "citationKey": "folch_combining_2023",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@article{folch_combining_2023, \ttitle = {Combining multi-fidelity modelling and asynchronous batch {Bayesian} {Optimization}}, \tvolume = {172}, \tissn = {00981354}, \turl = {https://linkinghub.elsevier.com/retrieve/pii/S0098135423000637}, \tdoi = {10.1016/j.compchemeng.2023.108194}, \tlanguage = {en}, \turldate = {2025-10-08}, \tjournal = {Computers \\& Chemical Engineering}, \tauthor = {Folch, Jose Pablo and Lee, Robert M. and Shafei, Behrang and Walz, David and Tsay, Calvin and Van Der Wilk, Mark and Misener, Ruth}, \tmonth = apr, \tyear = {2023}, \tpages = {108194}, }"
    },
    {
      "id": 5,
      "doi": "10.1016/j.jmva.2009.03.005",
      "pdf": "",
      "url": "https://linkinghub.elsevier.com/retrieve/pii/S0047259X0900061X",
      "date": "2010-01-01",
      "isbn": "",
      "issn": "0047259X",
      "link": "https://linkinghub.elsevier.com/retrieve/pii/S0047259X0900061X",
      "note": "",
      "text": "",
      "year": "2010",
      "month": "",
      "pages": "409--418",
      "title": "Cokriging for spatial functional data",
      "number": "2",
      "school": "",
      "series": "",
      "volume": "101",
      "address": "",
      "authors": "Nerini, David and Monestiez, Pascal and Manté, Claude",
      "chapter": "",
      "edition": "",
      "journal": "Journal of Multivariate Analysis",
      "abstract": "",
      "bibtexId": "nerini_cokriging_2010",
      "keywords": "",
      "booktitle": "",
      "entryType": "article",
      "publisher": "",
      "categories": [],
      "citationKey": "nerini_cokriging_2010",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@article{nerini_cokriging_2010, \ttitle = {Cokriging for spatial functional data}, \tvolume = {101}, \tcopyright = {https://www.elsevier.com/tdm/userlicense/1.0/}, \tissn = {0047259X}, \turl = {https://linkinghub.elsevier.com/retrieve/pii/S0047259X0900061X}, \tdoi = {10.1016/j.jmva.2009.03.005}, \tlanguage = {en}, \tnumber = {2}, \turldate = {2025-10-07}, \tjournal = {Journal of Multivariate Analysis}, \tauthor = {Nerini, David and Monestiez, Pascal and Manté, Claude}, \tmonth = feb, \tyear = {2010}, \tpages = {409--418}, }"
    },
    {
      "id": 6,
      "doi": "10.1016/j.ress.2019.106728",
      "pdf": "",
      "url": "https://linkinghub.elsevier.com/retrieve/pii/S0951832018311232",
      "date": "2020-01-01",
      "isbn": "",
      "issn": "09518320",
      "link": "https://linkinghub.elsevier.com/retrieve/pii/S0951832018311232",
      "note": "",
      "text": "",
      "year": "2020",
      "month": "",
      "pages": "106728",
      "title": "Adaptive calibration of a computer code with time-series output",
      "number": "",
      "school": "",
      "series": "",
      "volume": "196",
      "address": "",
      "authors": "Perrin, G.",
      "chapter": "",
      "edition": "",
      "journal": "Reliability Engineering \\& System Safety",
      "abstract": "",
      "bibtexId": "perrin_adaptive_2020",
      "keywords": "",
      "booktitle": "",
      "entryType": "article",
      "publisher": "",
      "categories": [
        "Other GP Litterature"
      ],
      "citationKey": "perrin_adaptive_2020",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@article{perrin_adaptive_2020, \ttitle = {Adaptive calibration of a computer code with time-series output}, \tvolume = {196}, \tissn = {09518320}, \turl = {https://linkinghub.elsevier.com/retrieve/pii/S0951832018311232}, \tdoi = {10.1016/j.ress.2019.106728}, \tlanguage = {en}, \turldate = {2025-10-07}, \tjournal = {Reliability Engineering \\& System Safety}, \tauthor = {Perrin, G.}, \tmonth = apr, \tyear = {2020}, \tpages = {106728}, }"
    },
    {
      "id": 7,
      "doi": "10.1198/106186008X384032",
      "pdf": "",
      "url": "http://www.tandfonline.com/doi/abs/10.1198/106186008X384032",
      "date": "2008-01-01",
      "isbn": "",
      "issn": "1061-8600, 1537-2715",
      "link": "http://www.tandfonline.com/doi/abs/10.1198/106186008X384032",
      "note": "",
      "text": "",
      "year": "2008",
      "month": "",
      "pages": "827--843",
      "title": "Efficient {Emulators",
      "number": "4",
      "school": "",
      "series": "",
      "volume": "17",
      "address": "",
      "authors": "Rougier, Jonathan",
      "chapter": "",
      "edition": "",
      "journal": "Journal of Computational and Graphical Statistics",
      "abstract": "",
      "bibtexId": "rougier_efficient_2008",
      "keywords": "",
      "booktitle": "",
      "entryType": "article",
      "publisher": "",
      "categories": [
        "Unsorted/unread",
        "POD"
      ],
      "citationKey": "rougier_efficient_2008",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@article{rougier_efficient_2008, \ttitle = {Efficient {Emulators} for {Multivariate} {Deterministic} {Functions}}, \tvolume = {17}, \tissn = {1061-8600, 1537-2715}, \turl = {http://www.tandfonline.com/doi/abs/10.1198/106186008X384032}, \tdoi = {10.1198/106186008X384032}, \tlanguage = {en}, \tnumber = {4}, \turldate = {2025-10-07}, \tjournal = {Journal of Computational and Graphical Statistics}, \tauthor = {Rougier, Jonathan}, \tmonth = dec, \tyear = {2008}, \tpages = {827--843}, }"
    },
    {
      "id": 8,
      "doi": "10.1007/s00180-016-0676-0",
      "pdf": "",
      "url": "http://link.springer.com/10.1007/s00180-016-0676-0",
      "date": "2017-01-01",
      "isbn": "",
      "issn": "0943-4062, 1613-9658",
      "link": "http://link.springer.com/10.1007/s00180-016-0676-0",
      "note": "",
      "text": "",
      "year": "2017",
      "month": "",
      "pages": "559--583",
      "title": "Uncertainty quantification for functional dependent random variables",
      "number": "2",
      "school": "",
      "series": "",
      "volume": "32",
      "address": "",
      "authors": "Nanty, Simon and Helbert, Céline and Marrel, Amandine and Pérot, Nadia and Prieur, Clémentine",
      "chapter": "",
      "edition": "",
      "journal": "Computational Statistics",
      "abstract": "",
      "bibtexId": "nanty_uncertainty_2017",
      "keywords": "",
      "booktitle": "",
      "entryType": "article",
      "publisher": "",
      "categories": [
        "Other GP Litterature"
      ],
      "citationKey": "nanty_uncertainty_2017",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@article{nanty_uncertainty_2017, \ttitle = {Uncertainty quantification for functional dependent random variables}, \tvolume = {32}, \tissn = {0943-4062, 1613-9658}, \turl = {http://link.springer.com/10.1007/s00180-016-0676-0}, \tdoi = {10.1007/s00180-016-0676-0}, \tlanguage = {en}, \tnumber = {2}, \turldate = {2025-10-07}, \tjournal = {Computational Statistics}, \tauthor = {Nanty, Simon and Helbert, Céline and Marrel, Amandine and Pérot, Nadia and Prieur, Clémentine}, \tmonth = jun, \tyear = {2017}, \tpages = {559--583}, }"
    },
    {
      "id": 9,
      "doi": "10.1007/s00158-023-03567-z",
      "pdf": "",
      "url": "https://link.springer.com/10.1007/s00158-023-03567-z",
      "date": "2023-01-01",
      "isbn": "",
      "issn": "1615-147X, 1615-1488",
      "link": "https://link.springer.com/10.1007/s00158-023-03567-z",
      "note": "",
      "text": "Abstract              Surrogate modelling is a popular approach for reducing the number of high fidelity simulations required within an engineering design optimization. Multi-fidelity surrogate modelling can further reduce this effort by exploiting low fidelity simulation data. Multi-output surrogate modelling techniques offer a way for categorical variables e.g. the choice of material, to be included within such models. While multi-fidelity multi-output surrogate modelling strategies have been proposed, to date only their predictive performance rather than optimization performance has been assessed. This paper considers three different multi-fidelity multi-output Kriging based surrogate modelling approaches and compares them to ordinary Kriging and multi-fidelity Kriging. The first approach modifies multi-fidelity Kriging to include multiple outputs whereas the second and third approaches model the different levels of simulation fidelity as different outputs within a multi-output Kriging model. Each of these techniques is assessed using three engineering design problems including the optimization of a gas turbine combustor in the presence of a topological variation, the optimization of a vibrating truss where the material can vary and finally, the parallel optimization of a family of airfoils.",
      "year": "2023",
      "month": "",
      "pages": "125",
      "title": "Applications of multi-fidelity multi-output {Kriging",
      "number": "6",
      "school": "",
      "series": "",
      "volume": "66",
      "address": "",
      "authors": "Toal, David J. J.",
      "chapter": "",
      "edition": "",
      "journal": "Structural and Multidisciplinary Optimization",
      "abstract": "Abstract              Surrogate modelling is a popular approach for reducing the number of high fidelity simulations required within an engineering design optimization. Multi-fidelity surrogate modelling can further reduce this effort by exploiting low fidelity simulation data. Multi-output surrogate modelling techniques offer a way for categorical variables e.g. the choice of material, to be included within such models. While multi-fidelity multi-output surrogate modelling strategies have been proposed, to date only their predictive performance rather than optimization performance has been assessed. This paper considers three different multi-fidelity multi-output Kriging based surrogate modelling approaches and compares them to ordinary Kriging and multi-fidelity Kriging. The first approach modifies multi-fidelity Kriging to include multiple outputs whereas the second and third approaches model the different levels of simulation fidelity as different outputs within a multi-output Kriging model. Each of these techniques is assessed using three engineering design problems including the optimization of a gas turbine combustor in the presence of a topological variation, the optimization of a vibrating truss where the material can vary and finally, the parallel optimization of a family of airfoils.",
      "bibtexId": "toal_applications_2023",
      "keywords": "",
      "booktitle": "",
      "entryType": "article",
      "publisher": "",
      "categories": [
        "Unsorted/unread",
        "MO-MF-GP"
      ],
      "citationKey": "toal_applications_2023",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@article{toal_applications_2023, \ttitle = {Applications of multi-fidelity multi-output {Kriging} to engineering design optimization}, \tvolume = {66}, \tissn = {1615-147X, 1615-1488}, \turl = {https://link.springer.com/10.1007/s00158-023-03567-z}, \tdoi = {10.1007/s00158-023-03567-z}, \tabstract = {Abstract              Surrogate modelling is a popular approach for reducing the number of high fidelity simulations required within an engineering design optimization. Multi-fidelity surrogate modelling can further reduce this effort by exploiting low fidelity simulation data. Multi-output surrogate modelling techniques offer a way for categorical variables e.g. the choice of material, to be included within such models. While multi-fidelity multi-output surrogate modelling strategies have been proposed, to date only their predictive performance rather than optimization performance has been assessed. This paper considers three different multi-fidelity multi-output Kriging based surrogate modelling approaches and compares them to ordinary Kriging and multi-fidelity Kriging. The first approach modifies multi-fidelity Kriging to include multiple outputs whereas the second and third approaches model the different levels of simulation fidelity as different outputs within a multi-output Kriging model. Each of these techniques is assessed using three engineering design problems including the optimization of a gas turbine combustor in the presence of a topological variation, the optimization of a vibrating truss where the material can vary and finally, the parallel optimization of a family of airfoils.}, \tlanguage = {en}, \tnumber = {6}, \turldate = {2025-10-07}, \tjournal = {Structural and Multidisciplinary Optimization}, \tauthor = {Toal, David J. J.}, \tmonth = jun, \tyear = {2023}, \tpages = {125}, }"
    },
    {
      "id": 10,
      "doi": "10.48550/arXiv.2109.11374",
      "pdf": "",
      "url": "http://arxiv.org/abs/2109.11374",
      "date": "2022-01-01",
      "isbn": "",
      "issn": "",
      "link": "http://arxiv.org/abs/2109.11374",
      "note": "arXiv:2109.11374",
      "text": "This paper considers the surrogate modeling of a complex numerical code in a multifidelity framework when the code output is a time series. Using an experimental design of the low-and high-fidelity code levels, an original Gaussian process regression method is proposed. The code output is expanded on a basis built from the experimental design. The first coefficients of the expansion of the code output are processed by a co-kriging approach. The last coefficients are collectively processed by a kriging approach with covariance tensorization. The resulting surrogate model taking into account the uncertainty in the basis construction is shown to have better performance in terms of prediction errors and uncertainty quantification than standard dimension reduction techniques.",
      "year": "2022",
      "month": "",
      "pages": "",
      "title": "Multi-fidelity surrogate modeling for time-series outputs",
      "number": "",
      "school": "",
      "series": "",
      "volume": "",
      "address": "",
      "authors": "Kerleguer, Baptiste",
      "chapter": "",
      "edition": "",
      "journal": "",
      "abstract": "This paper considers the surrogate modeling of a complex numerical code in a multifidelity framework when the code output is a time series. Using an experimental design of the low-and high-fidelity code levels, an original Gaussian process regression method is proposed. The code output is expanded on a basis built from the experimental design. The first coefficients of the expansion of the code output are processed by a co-kriging approach. The last coefficients are collectively processed by a kriging approach with covariance tensorization. The resulting surrogate model taking into account the uncertainty in the basis construction is shown to have better performance in terms of prediction errors and uncertainty quantification than standard dimension reduction techniques.",
      "bibtexId": "kerleguer_multi-fidelity_2022",
      "keywords": "Mathematics - Statistics Theory, Statistics - Statistics Theory",
      "booktitle": "",
      "entryType": "misc",
      "publisher": "arXiv",
      "categories": [
        "MF-GP",
        "MF-GP TS",
        "MF-ARGP"
      ],
      "citationKey": "kerleguer_multi-fidelity_2022",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@misc{kerleguer_multi-fidelity_2022, \ttitle = {Multi-fidelity surrogate modeling for time-series outputs}, \turl = {http://arxiv.org/abs/2109.11374}, \tdoi = {10.48550/arXiv.2109.11374}, \tabstract = {This paper considers the surrogate modeling of a complex numerical code in a multifidelity framework when the code output is a time series. Using an experimental design of the low-and high-fidelity code levels, an original Gaussian process regression method is proposed. The code output is expanded on a basis built from the experimental design. The first coefficients of the expansion of the code output are processed by a co-kriging approach. The last coefficients are collectively processed by a kriging approach with covariance tensorization. The resulting surrogate model taking into account the uncertainty in the basis construction is shown to have better performance in terms of prediction errors and uncertainty quantification than standard dimension reduction techniques.}, \turldate = {2025-10-07}, \tpublisher = {arXiv}, \tauthor = {Kerleguer, Baptiste}, \tmonth = feb, \tyear = {2022}, \tnote = {arXiv:2109.11374}, \tkeywords = {Mathematics - Statistics Theory, Statistics - Statistics Theory}, }"
    },
    {
      "id": 11,
      "doi": "10.48550/arXiv.2407.02476",
      "pdf": "",
      "url": "http://arxiv.org/abs/2407.02476",
      "date": "2025-01-01",
      "isbn": "",
      "issn": "",
      "link": "http://arxiv.org/abs/2407.02476",
      "note": "arXiv:2407.02476",
      "text": "The Multi-Output Gaussian Process is is a popular tool for modelling data from multiple sources. A typical choice to build a covariance function for a MOGP is the Linear Model of Coregionalization (LMC) which parametrically models the covariance between outputs. The Latent Variable MOGP (LV-MOGP) generalises this idea by modelling the covariance between outputs using a kernel applied to latent variables, one per output, leading to a flexible MOGP model that allows efficient generalization to new outputs with few data points. Computational complexity in LV-MOGP grows linearly with the number of outputs, which makes it unsuitable for problems with a large number of outputs. In this paper, we propose a stochastic variational inference approach for the LV-MOGP that allows mini-batches for both inputs and outputs, making computational complexity per training iteration independent of the number of outputs.",
      "year": "2025",
      "month": "",
      "pages": "",
      "title": "Scalable {Multi",
      "number": "",
      "school": "",
      "series": "",
      "volume": "",
      "address": "",
      "authors": "Jiang, Xiaoyu and Georgaka, Sokratia and Rattray, Magnus and Álvarez, Mauricio A.",
      "chapter": "",
      "edition": "",
      "journal": "",
      "abstract": "The Multi-Output Gaussian Process is is a popular tool for modelling data from multiple sources. A typical choice to build a covariance function for a MOGP is the Linear Model of Coregionalization (LMC) which parametrically models the covariance between outputs. The Latent Variable MOGP (LV-MOGP) generalises this idea by modelling the covariance between outputs using a kernel applied to latent variables, one per output, leading to a flexible MOGP model that allows efficient generalization to new outputs with few data points. Computational complexity in LV-MOGP grows linearly with the number of outputs, which makes it unsuitable for problems with a large number of outputs. In this paper, we propose a stochastic variational inference approach for the LV-MOGP that allows mini-batches for both inputs and outputs, making computational complexity per training iteration independent of the number of outputs.",
      "bibtexId": "jiang_scalable_2025",
      "keywords": "Computer Science - Machine Learning, Statistics - Machine Learning",
      "booktitle": "",
      "entryType": "misc",
      "publisher": "arXiv",
      "categories": [
        "Unsorted/unread",
        "MO-MF-GP"
      ],
      "citationKey": "jiang_scalable_2025",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@misc{jiang_scalable_2025, \ttitle = {Scalable {Multi}-{Output} {Gaussian} {Processes} with {Stochastic} {Variational} {Inference}}, \turl = {http://arxiv.org/abs/2407.02476}, \tdoi = {10.48550/arXiv.2407.02476}, \tabstract = {The Multi-Output Gaussian Process is is a popular tool for modelling data from multiple sources. A typical choice to build a covariance function for a MOGP is the Linear Model of Coregionalization (LMC) which parametrically models the covariance between outputs. The Latent Variable MOGP (LV-MOGP) generalises this idea by modelling the covariance between outputs using a kernel applied to latent variables, one per output, leading to a flexible MOGP model that allows efficient generalization to new outputs with few data points. Computational complexity in LV-MOGP grows linearly with the number of outputs, which makes it unsuitable for problems with a large number of outputs. In this paper, we propose a stochastic variational inference approach for the LV-MOGP that allows mini-batches for both inputs and outputs, making computational complexity per training iteration independent of the number of outputs.}, \turldate = {2025-10-07}, \tpublisher = {arXiv}, \tauthor = {Jiang, Xiaoyu and Georgaka, Sokratia and Rattray, Magnus and Álvarez, Mauricio A.}, \tmonth = jun, \tyear = {2025}, \tnote = {arXiv:2407.02476}, \tkeywords = {Computer Science - Machine Learning, Statistics - Machine Learning}, }"
    },
    {
      "id": 12,
      "doi": "10.1098/rsfs.2018.0083",
      "pdf": "",
      "url": "https://royalsocietypublishing.org/doi/10.1098/rsfs.2018.0083",
      "date": "2019-01-01",
      "isbn": "",
      "issn": "2042-8898, 2042-8901",
      "link": "https://royalsocietypublishing.org/doi/10.1098/rsfs.2018.0083",
      "note": "",
      "text": "In statistical modelling with Gaussian process regression, it has been shown that combining (few) high-fidelity data with (many) low-fidelity data can enhance prediction accuracy, compared to prediction based on the few high-fidelity data only. Such information fusion techniques for multi-fidelity data commonly approach the high-fidelity model                f                h                (                t                ) as a function of                two                variables (                t                ,                s                ), and then use                f                l                (                t                ) as the                s                data. More generally, the high-fidelity model can be written as a function of several variables (                t                ,                s                1                ,                s                2                ….); the low-fidelity model                f                l                and, say, some of its derivatives can then be substituted for these variables. In this paper, we will explore mathematical algorithms for multi-fidelity information fusion that use such an approach towards improving the representation of the high-fidelity function with only a few training data points. Given that                f                h                may not be a simple function—and sometimes not even a function—of                f                l                , we demonstrate that using additional functions of                t                , such as derivatives or shifts of                f                l                , can drastically improve the approximation of                f                h                through Gaussian processes. We also point out a connection with ‘embedology’ techniques from topology and dynamical systems. Our illustrative examples range from instructive caricatures to computational biology models, such as Hodgkin–Huxley neural oscillations.",
      "year": "2019",
      "month": "",
      "pages": "20180083",
      "title": "Linking {Gaussian",
      "number": "3",
      "school": "",
      "series": "",
      "volume": "9",
      "address": "",
      "authors": "Lee, Seungjoon and Dietrich, Felix and Karniadakis, George E. and Kevrekidis, Ioannis G.",
      "chapter": "",
      "edition": "",
      "journal": "Interface Focus",
      "abstract": "In statistical modelling with Gaussian process regression, it has been shown that combining (few) high-fidelity data with (many) low-fidelity data can enhance prediction accuracy, compared to prediction based on the few high-fidelity data only. Such information fusion techniques for multi-fidelity data commonly approach the high-fidelity model                f                h                (                t                ) as a function of                two                variables (                t                ,                s                ), and then use                f                l                (                t                ) as the                s                data. More generally, the high-fidelity model can be written as a function of several variables (                t                ,                s                1                ,                s                2                ….); the low-fidelity model                f                l                and, say, some of its derivatives can then be substituted for these variables. In this paper, we will explore mathematical algorithms for multi-fidelity information fusion that use such an approach towards improving the representation of the high-fidelity function with only a few training data points. Given that                f                h                may not be a simple function—and sometimes not even a function—of                f                l                , we demonstrate that using additional functions of                t                , such as derivatives or shifts of                f                l                , can drastically improve the approximation of                f                h                through Gaussian processes. We also point out a connection with ‘embedology’ techniques from topology and dynamical systems. Our illustrative examples range from instructive caricatures to computational biology models, such as Hodgkin–Huxley neural oscillations.",
      "bibtexId": "lee_linking_2019",
      "keywords": "",
      "booktitle": "",
      "entryType": "article",
      "publisher": "",
      "categories": [
        "MF-GP",
        "MF-NARGP"
      ],
      "citationKey": "lee_linking_2019",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@article{lee_linking_2019, \ttitle = {Linking {Gaussian} process regression with data-driven manifold embeddings for nonlinear data fusion}, \tvolume = {9}, \tissn = {2042-8898, 2042-8901}, \turl = {https://royalsocietypublishing.org/doi/10.1098/rsfs.2018.0083}, \tdoi = {10.1098/rsfs.2018.0083}, \tabstract = {In statistical modelling with Gaussian process regression, it has been shown that combining (few) high-fidelity data with (many) low-fidelity data can enhance prediction accuracy, compared to prediction based on the few high-fidelity data only. Such information fusion techniques for multi-fidelity data commonly approach the high-fidelity model                f                h                (                t                ) as a function of                two                variables (                t                ,                s                ), and then use                f                l                (                t                ) as the                s                data. More generally, the high-fidelity model can be written as a function of several variables (                t                ,                s                1                ,                s                2                ….); the low-fidelity model                f                l                and, say, some of its derivatives can then be substituted for these variables. In this paper, we will explore mathematical algorithms for multi-fidelity information fusion that use such an approach towards improving the representation of the high-fidelity function with only a few training data points. Given that                f                h                may not be a simple function—and sometimes not even a function—of                f                l                , we demonstrate that using additional functions of                t                , such as derivatives or shifts of                f                l                , can drastically improve the approximation of                f                h                through Gaussian processes. We also point out a connection with ‘embedology’ techniques from topology and dynamical systems. Our illustrative examples range from instructive caricatures to computational biology models, such as Hodgkin–Huxley neural oscillations.}, \tlanguage = {en}, \tnumber = {3}, \turldate = {2025-10-07}, \tjournal = {Interface Focus}, \tauthor = {Lee, Seungjoon and Dietrich, Felix and Karniadakis, George E. and Kevrekidis, Ioannis G.}, \tmonth = jun, \tyear = {2019}, \tpages = {20180083}, }"
    },
    {
      "id": 13,
      "doi": "10.2514/6.2022-3938",
      "pdf": "",
      "url": "https://arc.aiaa.org/doi/10.2514/6.2022-3938",
      "date": "2022-01-01",
      "isbn": "9781624106354",
      "issn": "",
      "link": "https://arc.aiaa.org/doi/10.2514/6.2022-3938",
      "note": "",
      "text": "",
      "year": "2022",
      "month": "",
      "pages": "",
      "title": "Multi-fidelity {Aerodynamic",
      "number": "",
      "school": "",
      "series": "",
      "volume": "",
      "address": "Chicago, IL \\& Virtual",
      "authors": "Zakrzewski, Alexander and Lange, Fabian and Hollmann, René",
      "chapter": "",
      "edition": "",
      "journal": "",
      "abstract": "",
      "bibtexId": "zakrzewski_multi-fidelity_2022",
      "keywords": "",
      "booktitle": "{AIAA",
      "entryType": "inproceedings",
      "publisher": "American Institute of Aeronautics and Astronautics",
      "categories": [
        "BO-GP",
        "Other GP Litterature"
      ],
      "citationKey": "zakrzewski_multi-fidelity_2022",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@inproceedings{zakrzewski_multi-fidelity_2022, \taddress = {Chicago, IL \\& Virtual}, \ttitle = {Multi-fidelity {Aerodynamic} {Design} {Process} for {Moveables} at {DLR} {Virtual} {Product} {House}}, \tisbn = {9781624106354}, \turl = {https://arc.aiaa.org/doi/10.2514/6.2022-3938}, \tdoi = {10.2514/6.2022-3938}, \tlanguage = {en}, \turldate = {2025-10-07}, \tbooktitle = {{AIAA} {AVIATION} 2022 {Forum}}, \tpublisher = {American Institute of Aeronautics and Astronautics}, \tauthor = {Zakrzewski, Alexander and Lange, Fabian and Hollmann, René}, \tmonth = jun, \tyear = {2022}, }"
    },
    {
      "id": 14,
      "doi": "10.1016/j.knosys.2022.109645",
      "pdf": "",
      "url": "https://linkinghub.elsevier.com/retrieve/pii/S0950705122008334",
      "date": "2022-01-01",
      "isbn": "",
      "issn": "09507051",
      "link": "https://linkinghub.elsevier.com/retrieve/pii/S0950705122008334",
      "note": "",
      "text": "",
      "year": "2022",
      "month": "",
      "pages": "109645",
      "title": "A multi-output multi-fidelity {Gaussian",
      "number": "",
      "school": "",
      "series": "",
      "volume": "254",
      "address": "",
      "authors": "Lin, Quan and Qian, Jiachang and Cheng, Yuansheng and Zhou, Qi and Hu, Jiexiang",
      "chapter": "",
      "edition": "",
      "journal": "Knowledge-Based Systems",
      "abstract": "",
      "bibtexId": "lin_multi-output_2022",
      "keywords": "",
      "booktitle": "",
      "entryType": "article",
      "publisher": "",
      "categories": [
        "Unsorted/unread",
        "MO-MF-GP"
      ],
      "citationKey": "lin_multi-output_2022",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@article{lin_multi-output_2022, \ttitle = {A multi-output multi-fidelity {Gaussian} process model for non-hierarchical low-fidelity data fusion}, \tvolume = {254}, \tissn = {09507051}, \turl = {https://linkinghub.elsevier.com/retrieve/pii/S0950705122008334}, \tdoi = {10.1016/j.knosys.2022.109645}, \tlanguage = {en}, \turldate = {2025-10-07}, \tjournal = {Knowledge-Based Systems}, \tauthor = {Lin, Quan and Qian, Jiachang and Cheng, Yuansheng and Zhou, Qi and Hu, Jiexiang}, \tmonth = oct, \tyear = {2022}, \tpages = {109645}, }"
    },
    {
      "id": 15,
      "doi": "10.48550/arXiv.2211.02465",
      "pdf": "",
      "url": "http://arxiv.org/abs/2211.02465",
      "date": "2022-01-01",
      "isbn": "",
      "issn": "",
      "link": "http://arxiv.org/abs/2211.02465",
      "note": "arXiv:2211.02465",
      "text": "In a fissile material, the inherent multiplicity of neutrons born through induced fissions leads to correlations in their detection statistics. The correlations between neutrons can be used to trace back some characteristics of the fissile material. This technique known as neutron noise analysis has applications in nuclear safeguards or waste identification. It provides a non-destructive examination method for an unknown fissile material. This is an example of an inverse problem where the cause is inferred from observations of the consequences. However, neutron correlation measurements are often noisy because of the stochastic nature of the underlying processes. This makes the resolution of the inverse problem more complex since the measurements are strongly dependent on the material characteristics. A minor change in the material properties can lead to very different outputs. Such an inverse problem is said to be ill-posed. For an ill-posed inverse problem the inverse uncertainty quantification is crucial. Indeed, seemingly low noise in the data can lead to strong uncertainties in the estimation of the material properties. Moreover, the analytical framework commonly used to describe neutron correlations relies on strong physical assumptions and is thus inherently biased. This paper addresses dual goals. Firstly, surrogate models are used to improve neutron correlations predictions and quantify the errors on those predictions. Then, the inverse uncertainty quantification is performed to include the impact of measurement error alongside the residual model bias.",
      "year": "2022",
      "month": "",
      "pages": "",
      "title": "Multi-output {Gaussian",
      "number": "",
      "school": "",
      "series": "",
      "volume": "",
      "address": "",
      "authors": "Lartaud, Paul and Humbert, Philippe and Garnier, Josselin",
      "chapter": "",
      "edition": "",
      "journal": "",
      "abstract": "In a fissile material, the inherent multiplicity of neutrons born through induced fissions leads to correlations in their detection statistics. The correlations between neutrons can be used to trace back some characteristics of the fissile material. This technique known as neutron noise analysis has applications in nuclear safeguards or waste identification. It provides a non-destructive examination method for an unknown fissile material. This is an example of an inverse problem where the cause is inferred from observations of the consequences. However, neutron correlation measurements are often noisy because of the stochastic nature of the underlying processes. This makes the resolution of the inverse problem more complex since the measurements are strongly dependent on the material characteristics. A minor change in the material properties can lead to very different outputs. Such an inverse problem is said to be ill-posed. For an ill-posed inverse problem the inverse uncertainty quantification is crucial. Indeed, seemingly low noise in the data can lead to strong uncertainties in the estimation of the material properties. Moreover, the analytical framework commonly used to describe neutron correlations relies on strong physical assumptions and is thus inherently biased. This paper addresses dual goals. Firstly, surrogate models are used to improve neutron correlations predictions and quantify the errors on those predictions. Then, the inverse uncertainty quantification is performed to include the impact of measurement error alongside the residual model bias.",
      "bibtexId": "lartaud_multi-output_2022",
      "keywords": "Nuclear Theory, Statistics - Applications, Statistics - Computation, Statistics - Machine Learning",
      "booktitle": "",
      "entryType": "misc",
      "publisher": "arXiv",
      "categories": [
        "Other GP Litterature",
        "MO-GP"
      ],
      "citationKey": "lartaud_multi-output_2022",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@misc{lartaud_multi-output_2022, \ttitle = {Multi-output {Gaussian} processes for inverse uncertainty quantification in neutron noise analysis}, \turl = {http://arxiv.org/abs/2211.02465}, \tdoi = {10.48550/arXiv.2211.02465}, \tabstract = {In a fissile material, the inherent multiplicity of neutrons born through induced fissions leads to correlations in their detection statistics. The correlations between neutrons can be used to trace back some characteristics of the fissile material. This technique known as neutron noise analysis has applications in nuclear safeguards or waste identification. It provides a non-destructive examination method for an unknown fissile material. This is an example of an inverse problem where the cause is inferred from observations of the consequences. However, neutron correlation measurements are often noisy because of the stochastic nature of the underlying processes. This makes the resolution of the inverse problem more complex since the measurements are strongly dependent on the material characteristics. A minor change in the material properties can lead to very different outputs. Such an inverse problem is said to be ill-posed. For an ill-posed inverse problem the inverse uncertainty quantification is crucial. Indeed, seemingly low noise in the data can lead to strong uncertainties in the estimation of the material properties. Moreover, the analytical framework commonly used to describe neutron correlations relies on strong physical assumptions and is thus inherently biased. This paper addresses dual goals. Firstly, surrogate models are used to improve neutron correlations predictions and quantify the errors on those predictions. Then, the inverse uncertainty quantification is performed to include the impact of measurement error alongside the residual model bias.}, \turldate = {2025-10-07}, \tpublisher = {arXiv}, \tauthor = {Lartaud, Paul and Humbert, Philippe and Garnier, Josselin}, \tmonth = nov, \tyear = {2022}, \tnote = {arXiv:2211.02465}, \tkeywords = {Nuclear Theory, Statistics - Applications, Statistics - Computation, Statistics - Machine Learning}, }"
    },
    {
      "id": 16,
      "doi": "10.1016/j.cie.2022.108746",
      "pdf": "",
      "url": "https://linkinghub.elsevier.com/retrieve/pii/S0360835222007343",
      "date": "2022-01-01",
      "isbn": "",
      "issn": "03608352",
      "link": "https://linkinghub.elsevier.com/retrieve/pii/S0360835222007343",
      "note": "",
      "text": "",
      "year": "2022",
      "month": "",
      "pages": "108746",
      "title": "A random forest with multi-fidelity {Gaussian",
      "number": "",
      "school": "",
      "series": "",
      "volume": "174",
      "address": "",
      "authors": "Ghosh, Mithun and Wu, Lang and Hao, Qing and Zhou, Qiang",
      "chapter": "",
      "edition": "",
      "journal": "Computers \\& Industrial Engineering",
      "abstract": "",
      "bibtexId": "ghosh_random_2022",
      "keywords": "",
      "booktitle": "",
      "entryType": "article",
      "publisher": "",
      "categories": [
        "Other MF-GP",
        "MF-GP"
      ],
      "citationKey": "ghosh_random_2022",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@article{ghosh_random_2022, \ttitle = {A random forest with multi-fidelity {Gaussian} process leaves for modeling multi-fidelity data with heterogeneity}, \tvolume = {174}, \tissn = {03608352}, \turl = {https://linkinghub.elsevier.com/retrieve/pii/S0360835222007343}, \tdoi = {10.1016/j.cie.2022.108746}, \tlanguage = {en}, \turldate = {2025-10-07}, \tjournal = {Computers \\& Industrial Engineering}, \tauthor = {Ghosh, Mithun and Wu, Lang and Hao, Qing and Zhou, Qiang}, \tmonth = dec, \tyear = {2022}, \tpages = {108746}, }"
    },
    {
      "id": 17,
      "doi": "10.1016/j.jcp.2024.113474",
      "pdf": "",
      "url": "https://linkinghub.elsevier.com/retrieve/pii/S0021999124007228",
      "date": "2025-01-01",
      "isbn": "",
      "issn": "00219991",
      "link": "https://linkinghub.elsevier.com/retrieve/pii/S0021999124007228",
      "note": "",
      "text": "",
      "year": "2025",
      "month": "",
      "pages": "113474",
      "title": "Gradient-enhanced deep {Gaussian",
      "number": "",
      "school": "",
      "series": "",
      "volume": "520",
      "address": "",
      "authors": "Bone, Viv and Van Der Heide, Chris and Mackle, Kieran and Jahn, Ingo and Dower, Peter M. and Manzie, Chris",
      "chapter": "",
      "edition": "",
      "journal": "Journal of Computational Physics",
      "abstract": "",
      "bibtexId": "bone_gradient-enhanced_2025",
      "keywords": "",
      "booktitle": "",
      "entryType": "article",
      "publisher": "",
      "categories": [
        "Other MF-GP",
        "MF-GP"
      ],
      "citationKey": "bone_gradient-enhanced_2025",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@article{bone_gradient-enhanced_2025, \ttitle = {Gradient-enhanced deep {Gaussian} processes for multifidelity modeling}, \tvolume = {520}, \tissn = {00219991}, \turl = {https://linkinghub.elsevier.com/retrieve/pii/S0021999124007228}, \tdoi = {10.1016/j.jcp.2024.113474}, \tlanguage = {en}, \turldate = {2025-10-07}, \tjournal = {Journal of Computational Physics}, \tauthor = {Bone, Viv and Van Der Heide, Chris and Mackle, Kieran and Jahn, Ingo and Dower, Peter M. and Manzie, Chris}, \tmonth = jan, \tyear = {2025}, \tpages = {113474}, }"
    },
    {
      "id": 19,
      "doi": "10.2514/6.2019-1973",
      "pdf": "",
      "url": "https://arc.aiaa.org/doi/10.2514/6.2019-1973",
      "date": "2019-01-01",
      "isbn": "",
      "issn": "",
      "link": "https://arc.aiaa.org/doi/10.2514/6.2019-1973",
      "note": "",
      "text": "",
      "year": "2019",
      "month": "",
      "pages": "",
      "title": "Multi-objective optimization using {Deep",
      "number": "",
      "school": "",
      "series": "{AIAA",
      "volume": "",
      "address": "",
      "authors": "Hebbal, Ali and Brevault, Loïc and Balesdent, Mathieu and Talbi, El-Ghazali and Melab, Nouredine",
      "chapter": "",
      "edition": "",
      "journal": "",
      "abstract": "",
      "bibtexId": "hebbal_multi-objective_2019-1",
      "keywords": "Aerospace Engineering, Aerospace Vehicle, Black Box, Computational Fluid Dynamics, Cumulative Distribution Function, Expectation Propagation, Multi Objective Evolutionary Algorithms, Optimization Algorithm, Solid Propellants, Surrogate Model",
      "booktitle": "{AIAA",
      "entryType": "incollection",
      "publisher": "American Institute of Aeronautics and Astronautics",
      "categories": [
        "BO-GP",
        "Other GP Litterature"
      ],
      "citationKey": "hebbal_multi-objective_2019-1",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@incollection{hebbal_multi-objective_2019-1, \tseries = {{AIAA} {SciTech} {Forum}}, \ttitle = {Multi-objective optimization using {Deep} {Gaussian} {Processes}: {Application} to {Aerospace} {Vehicle} {Design}}, \tshorttitle = {Multi-objective optimization using {Deep} {Gaussian} {Processes}}, \turl = {https://arc.aiaa.org/doi/10.2514/6.2019-1973}, \turldate = {2025-10-07}, \tbooktitle = {{AIAA} {Scitech} 2019 {Forum}}, \tpublisher = {American Institute of Aeronautics and Astronautics}, \tauthor = {Hebbal, Ali and Brevault, Loïc and Balesdent, Mathieu and Talbi, El-Ghazali and Melab, Nouredine}, \tmonth = jan, \tyear = {2019}, \tdoi = {10.2514/6.2019-1973}, \tkeywords = {Aerospace Engineering, Aerospace Vehicle, Black Box, Computational Fluid Dynamics, Cumulative Distribution Function, Expectation Propagation, Multi Objective Evolutionary Algorithms, Optimization Algorithm, Solid Propellants, Surrogate Model}, }"
    },
    {
      "id": 20,
      "doi": "10.1016/j.amc.2017.10.055",
      "pdf": "",
      "url": "https://linkinghub.elsevier.com/retrieve/pii/S0096300317307646",
      "date": "2018-01-01",
      "isbn": "",
      "issn": "00963003",
      "link": "https://linkinghub.elsevier.com/retrieve/pii/S0096300317307646",
      "note": "",
      "text": "",
      "year": "2018",
      "month": "",
      "pages": "120--131",
      "title": "Extended {Co",
      "number": "",
      "school": "",
      "series": "",
      "volume": "323",
      "address": "",
      "authors": "Xiao, Manyu and Zhang, Guohua and Breitkopf, Piotr and Villon, Pierre and Zhang, Weihong",
      "chapter": "",
      "edition": "",
      "journal": "Applied Mathematics and Computation",
      "abstract": "",
      "bibtexId": "xiao_extended_2018",
      "keywords": "",
      "booktitle": "",
      "entryType": "article",
      "publisher": "",
      "categories": [
        "MF-GP",
        "Other MF-GP"
      ],
      "citationKey": "xiao_extended_2018",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@article{xiao_extended_2018, \ttitle = {Extended {Co}-{Kriging} interpolation method based on multi-fidelity data}, \tvolume = {323}, \tissn = {00963003}, \turl = {https://linkinghub.elsevier.com/retrieve/pii/S0096300317307646}, \tdoi = {10.1016/j.amc.2017.10.055}, \tlanguage = {en}, \turldate = {2025-10-07}, \tjournal = {Applied Mathematics and Computation}, \tauthor = {Xiao, Manyu and Zhang, Guohua and Breitkopf, Piotr and Villon, Pierre and Zhang, Weihong}, \tmonth = apr, \tyear = {2018}, \tpages = {120--131}, }"
    },
    {
      "id": 21,
      "doi": "10.48550/arXiv.1903.07320",
      "pdf": "",
      "url": "http://arxiv.org/abs/1903.07320",
      "date": "2019-01-01",
      "isbn": "",
      "issn": "",
      "link": "http://arxiv.org/abs/1903.07320",
      "note": "arXiv:1903.07320",
      "text": "Multi-fidelity methods are prominently used when cheaply-obtained, but possibly biased and noisy, observations must be effectively combined with limited or expensive true data in order to construct reliable models. This arises in both fundamental machine learning procedures such as Bayesian optimization, as well as more practical science and engineering applications. In this paper we develop a novel multi-fidelity model which treats layers of a deep Gaussian process as fidelity levels, and uses a variational inference scheme to propagate uncertainty across them. This allows for capturing nonlinear correlations between fidelities with lower risk of overfitting than existing methods exploiting compositional structure, which are conversely burdened by structural assumptions and constraints. We show that the proposed approach makes substantial improvements in quantifying and propagating uncertainty in multi-fidelity set-ups, which in turn improves their effectiveness in decision making pipelines.",
      "year": "2019",
      "month": "",
      "pages": "",
      "title": "Deep {Gaussian",
      "number": "",
      "school": "",
      "series": "",
      "volume": "",
      "address": "",
      "authors": "Cutajar, Kurt and Pullin, Mark and Damianou, Andreas and Lawrence, Neil and González, Javier",
      "chapter": "",
      "edition": "",
      "journal": "",
      "abstract": "Multi-fidelity methods are prominently used when cheaply-obtained, but possibly biased and noisy, observations must be effectively combined with limited or expensive true data in order to construct reliable models. This arises in both fundamental machine learning procedures such as Bayesian optimization, as well as more practical science and engineering applications. In this paper we develop a novel multi-fidelity model which treats layers of a deep Gaussian process as fidelity levels, and uses a variational inference scheme to propagate uncertainty across them. This allows for capturing nonlinear correlations between fidelities with lower risk of overfitting than existing methods exploiting compositional structure, which are conversely burdened by structural assumptions and constraints. We show that the proposed approach makes substantial improvements in quantifying and propagating uncertainty in multi-fidelity set-ups, which in turn improves their effectiveness in decision making pipelines.",
      "bibtexId": "cutajar_deep_2019",
      "keywords": "Computer Science - Machine Learning, Statistics - Machine Learning",
      "booktitle": "",
      "entryType": "misc",
      "publisher": "arXiv",
      "categories": [
        "MF-GP",
        "MF-DGP"
      ],
      "citationKey": "cutajar_deep_2019",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@misc{cutajar_deep_2019, \ttitle = {Deep {Gaussian} {Processes} for {Multi}-fidelity {Modeling}}, \turl = {http://arxiv.org/abs/1903.07320}, \tdoi = {10.48550/arXiv.1903.07320}, \tabstract = {Multi-fidelity methods are prominently used when cheaply-obtained, but possibly biased and noisy, observations must be effectively combined with limited or expensive true data in order to construct reliable models. This arises in both fundamental machine learning procedures such as Bayesian optimization, as well as more practical science and engineering applications. In this paper we develop a novel multi-fidelity model which treats layers of a deep Gaussian process as fidelity levels, and uses a variational inference scheme to propagate uncertainty across them. This allows for capturing nonlinear correlations between fidelities with lower risk of overfitting than existing methods exploiting compositional structure, which are conversely burdened by structural assumptions and constraints. We show that the proposed approach makes substantial improvements in quantifying and propagating uncertainty in multi-fidelity set-ups, which in turn improves their effectiveness in decision making pipelines.}, \turldate = {2025-10-06}, \tpublisher = {arXiv}, \tauthor = {Cutajar, Kurt and Pullin, Mark and Damianou, Andreas and Lawrence, Neil and González, Javier}, \tmonth = mar, \tyear = {2019}, \tnote = {arXiv:1903.07320}, \tkeywords = {Computer Science - Machine Learning, Statistics - Machine Learning}, }"
    },
    {
      "id": 22,
      "doi": "10.1098/rspa.2016.0751",
      "pdf": "",
      "url": "https://royalsocietypublishing.org/doi/10.1098/rspa.2016.0751",
      "date": "2017-01-01",
      "isbn": "",
      "issn": "1364-5021, 1471-2946",
      "link": "https://royalsocietypublishing.org/doi/10.1098/rspa.2016.0751",
      "note": "",
      "text": "Multi-fidelity modelling enables accurate inference of quantities of interest by synergistically combining realizations of low-cost/low-fidelity models with a small set of high-fidelity observations. This is particularly effective when the low- and high-fidelity models exhibit strong correlations, and can lead to significant computational gains over approaches that solely rely on high-fidelity models. However, in many cases of practical interest, low-fidelity models can only be well correlated to their high-fidelity counterparts for a specific range of input parameters, and potentially return wrong trends and erroneous predictions if probed outside of their validity regime. Here we put forth a probabilistic framework based on Gaussian process regression and nonlinear autoregressive schemes that is capable of learning complex nonlinear and space-dependent cross-correlations between models of variable fidelity, and can effectively safeguard against low-fidelity models that provide wrong trends. This introduces a new class of multi-fidelity information fusion algorithms that provide a fundamental extension to the existing linear autoregressive methodologies, while still maintaining the same algorithmic complexity and overall computational cost. The performance of the proposed methods is tested in several benchmark problems involving both synthetic and real multi-fidelity datasets from computational fluid dynamics simulations.",
      "year": "2017",
      "month": "",
      "pages": "20160751",
      "title": "Nonlinear information fusion algorithms for data-efficient multi-fidelity modelling",
      "number": "2198",
      "school": "",
      "series": "",
      "volume": "473",
      "address": "",
      "authors": "Perdikaris, P. and Raissi, M. and Damianou, A. and Lawrence, N. D. and Karniadakis, G. E.",
      "chapter": "",
      "edition": "",
      "journal": "Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences",
      "abstract": "Multi-fidelity modelling enables accurate inference of quantities of interest by synergistically combining realizations of low-cost/low-fidelity models with a small set of high-fidelity observations. This is particularly effective when the low- and high-fidelity models exhibit strong correlations, and can lead to significant computational gains over approaches that solely rely on high-fidelity models. However, in many cases of practical interest, low-fidelity models can only be well correlated to their high-fidelity counterparts for a specific range of input parameters, and potentially return wrong trends and erroneous predictions if probed outside of their validity regime. Here we put forth a probabilistic framework based on Gaussian process regression and nonlinear autoregressive schemes that is capable of learning complex nonlinear and space-dependent cross-correlations between models of variable fidelity, and can effectively safeguard against low-fidelity models that provide wrong trends. This introduces a new class of multi-fidelity information fusion algorithms that provide a fundamental extension to the existing linear autoregressive methodologies, while still maintaining the same algorithmic complexity and overall computational cost. The performance of the proposed methods is tested in several benchmark problems involving both synthetic and real multi-fidelity datasets from computational fluid dynamics simulations.",
      "bibtexId": "perdikaris_nonlinear_2017",
      "keywords": "",
      "booktitle": "",
      "entryType": "article",
      "publisher": "",
      "categories": [
        "MF-NARGP",
        "MF-GP"
      ],
      "citationKey": "perdikaris_nonlinear_2017",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@article{perdikaris_nonlinear_2017, \ttitle = {Nonlinear information fusion algorithms for data-efficient multi-fidelity modelling}, \tvolume = {473}, \tissn = {1364-5021, 1471-2946}, \turl = {https://royalsocietypublishing.org/doi/10.1098/rspa.2016.0751}, \tdoi = {10.1098/rspa.2016.0751}, \tabstract = {Multi-fidelity modelling enables accurate inference of quantities of interest by synergistically combining realizations of low-cost/low-fidelity models with a small set of high-fidelity observations. This is particularly effective when the low- and high-fidelity models exhibit strong correlations, and can lead to significant computational gains over approaches that solely rely on high-fidelity models. However, in many cases of practical interest, low-fidelity models can only be well correlated to their high-fidelity counterparts for a specific range of input parameters, and potentially return wrong trends and erroneous predictions if probed outside of their validity regime. Here we put forth a probabilistic framework based on Gaussian process regression and nonlinear autoregressive schemes that is capable of learning complex nonlinear and space-dependent cross-correlations between models of variable fidelity, and can effectively safeguard against low-fidelity models that provide wrong trends. This introduces a new class of multi-fidelity information fusion algorithms that provide a fundamental extension to the existing linear autoregressive methodologies, while still maintaining the same algorithmic complexity and overall computational cost. The performance of the proposed methods is tested in several benchmark problems involving both synthetic and real multi-fidelity datasets from computational fluid dynamics simulations.}, \tlanguage = {en}, \tnumber = {2198}, \turldate = {2025-10-06}, \tjournal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences}, \tauthor = {Perdikaris, P. and Raissi, M. and Damianou, A. and Lawrence, N. D. and Karniadakis, G. E.}, \tmonth = feb, \tyear = {2017}, \tpages = {20160751}, }"
    },
    {
      "id": 23,
      "doi": "10.1016/j.ast.2020.106339",
      "pdf": "",
      "url": "https://linkinghub.elsevier.com/retrieve/pii/S127096382031021X",
      "date": "2020-01-01",
      "isbn": "",
      "issn": "12709638",
      "link": "https://linkinghub.elsevier.com/retrieve/pii/S127096382031021X",
      "note": "",
      "text": "",
      "year": "2020",
      "month": "",
      "pages": "106339",
      "title": "Overview of {Gaussian",
      "number": "",
      "school": "",
      "series": "",
      "volume": "107",
      "address": "",
      "authors": "Brevault, Loïc and Balesdent, Mathieu and Hebbal, Ali",
      "chapter": "",
      "edition": "",
      "journal": "Aerospace Science and Technology",
      "abstract": "",
      "bibtexId": "brevault_overview_2020",
      "keywords": "",
      "booktitle": "",
      "entryType": "article",
      "publisher": "",
      "categories": [
        "MF-GP",
        "Application MF-GP"
      ],
      "citationKey": "brevault_overview_2020",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@article{brevault_overview_2020, \ttitle = {Overview of {Gaussian} process based multi-fidelity techniques with variable relationship between fidelities, application to aerospace systems}, \tvolume = {107}, \tissn = {12709638}, \turl = {https://linkinghub.elsevier.com/retrieve/pii/S127096382031021X}, \tdoi = {10.1016/j.ast.2020.106339}, \tlanguage = {en}, \turldate = {2025-10-06}, \tjournal = {Aerospace Science and Technology}, \tauthor = {Brevault, Loïc and Balesdent, Mathieu and Hebbal, Ali}, \tmonth = dec, \tyear = {2020}, \tpages = {106339}, }"
    },
    {
      "id": 25,
      "doi": "10.1016/j.compfluid.2018.07.021",
      "pdf": "",
      "url": "https://www.sciencedirect.com/science/article/pii/S0045793018304250",
      "date": "2019-01-01",
      "isbn": "",
      "issn": "0045-7930",
      "link": "https://www.sciencedirect.com/science/article/pii/S0045793018304250",
      "note": "",
      "text": "This paper considers the creation of parametric surrogate models for applications in science and engineering where the goal is to predict high-dimensional output quantities of interest, such as pressure, temperature and strain fields. The proposed methodology develops a low-dimensional parametrization of these quantities of interest using the proper orthogonal decomposition (POD), and combines this parametrization with machine learning methods to learn the map between the input parameters and the POD expansion coefficients. The use of particular solutions in the POD expansion provides a way to embed physical constraints, such as boundary conditions and other features of the solution that must be preserved. The relative costs and effectiveness of four different machine learning techniques—neural networks, multivariate polynomial regression, k-nearest-neighbors and decision trees—are explored through two engineering examples. The first example considers prediction of the pressure field around an airfoil, while the second considers prediction of the strain field over a damaged composite panel. The case studies demonstrate the importance of embedding physical constraints within learned models, and also highlight the important point that the amount of model training data available in an engineering setting is often much less than it is in other machine learning applications, making it essential to incorporate knowledge from physical models.",
      "year": "2019",
      "month": "",
      "pages": "704--717",
      "title": "Projection-based model reduction: {Formulations",
      "number": "",
      "school": "",
      "series": "",
      "volume": "179",
      "address": "",
      "authors": "Swischuk, Renee and Mainini, Laura and Peherstorfer, Benjamin and Willcox, Karen",
      "chapter": "",
      "edition": "",
      "journal": "Computers \\& Fluids",
      "abstract": "This paper considers the creation of parametric surrogate models for applications in science and engineering where the goal is to predict high-dimensional output quantities of interest, such as pressure, temperature and strain fields. The proposed methodology develops a low-dimensional parametrization of these quantities of interest using the proper orthogonal decomposition (POD), and combines this parametrization with machine learning methods to learn the map between the input parameters and the POD expansion coefficients. The use of particular solutions in the POD expansion provides a way to embed physical constraints, such as boundary conditions and other features of the solution that must be preserved. The relative costs and effectiveness of four different machine learning techniques—neural networks, multivariate polynomial regression, k-nearest-neighbors and decision trees—are explored through two engineering examples. The first example considers prediction of the pressure field around an airfoil, while the second considers prediction of the strain field over a damaged composite panel. The case studies demonstrate the importance of embedding physical constraints within learned models, and also highlight the important point that the amount of model training data available in an engineering setting is often much less than it is in other machine learning applications, making it essential to incorporate knowledge from physical models.",
      "bibtexId": "swischuk_projection-based_2019",
      "keywords": "Data-driven reduced models, Model reduction, Physics-based machine learning, Proper orthogonal decomposition, Surrogate models",
      "booktitle": "",
      "entryType": "article",
      "publisher": "",
      "categories": [
        "POD",
        "Unsorted/unread"
      ],
      "citationKey": "swischuk_projection-based_2019",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@article{swischuk_projection-based_2019, \ttitle = {Projection-based model reduction: {Formulations} for physics-based machine learning}, \tvolume = {179}, \tissn = {0045-7930}, \tshorttitle = {Projection-based model reduction}, \turl = {https://www.sciencedirect.com/science/article/pii/S0045793018304250}, \tdoi = {10.1016/j.compfluid.2018.07.021}, \tabstract = {This paper considers the creation of parametric surrogate models for applications in science and engineering where the goal is to predict high-dimensional output quantities of interest, such as pressure, temperature and strain fields. The proposed methodology develops a low-dimensional parametrization of these quantities of interest using the proper orthogonal decomposition (POD), and combines this parametrization with machine learning methods to learn the map between the input parameters and the POD expansion coefficients. The use of particular solutions in the POD expansion provides a way to embed physical constraints, such as boundary conditions and other features of the solution that must be preserved. The relative costs and effectiveness of four different machine learning techniques—neural networks, multivariate polynomial regression, k-nearest-neighbors and decision trees—are explored through two engineering examples. The first example considers prediction of the pressure field around an airfoil, while the second considers prediction of the strain field over a damaged composite panel. The case studies demonstrate the importance of embedding physical constraints within learned models, and also highlight the important point that the amount of model training data available in an engineering setting is often much less than it is in other machine learning applications, making it essential to incorporate knowledge from physical models.}, \turldate = {2025-10-06}, \tjournal = {Computers \\& Fluids}, \tauthor = {Swischuk, Renee and Mainini, Laura and Peherstorfer, Benjamin and Willcox, Karen}, \tmonth = jan, \tyear = {2019}, \tkeywords = {Data-driven reduced models, Model reduction, Physics-based machine learning, Proper orthogonal decomposition, Surrogate models}, \tpages = {704--717}, }"
    },
    {
      "id": 26,
      "doi": "10.48550/arXiv.2505.15557",
      "pdf": "",
      "url": "http://arxiv.org/abs/2505.15557",
      "date": "2025-01-01",
      "isbn": "",
      "issn": "",
      "link": "http://arxiv.org/abs/2505.15557",
      "note": "arXiv:2505.15557",
      "text": "Gaussian processes (GPs) furnish accurate nonlinear predictions with well-calibrated uncertainty. However, the typical GP setup has a built-in stationarity assumption, making it ill-suited for modeling data from processes with sudden changes, or \"jumps\" in the output variable. The \"jump GP\" (JGP) was developed for modeling data from such processes, combining local GPs and latent \"level\" variables under a joint inferential framework. But joint modeling can be fraught with difficulty. We aim to simplify by suggesting a more modular setup, eschewing joint inference but retaining the main JGP themes: (a) learning optimal neighborhood sizes that locally respect manifolds of discontinuity; and (b) a new cluster-based (latent) feature to capture regions of distinct output levels on both sides of the manifold. We show that each of (a) and (b) separately leads to dramatic improvements when modeling processes with jumps. In tandem (but without requiring joint inference) that benefit is compounded, as illustrated on real and synthetic benchmark examples from the recent literature.",
      "year": "2025",
      "month": "",
      "pages": "",
      "title": "Modular {Jump",
      "number": "",
      "school": "",
      "series": "",
      "volume": "",
      "address": "",
      "authors": "Flowers, Anna R. and Franck, Christopher T. and Binois, Mickaël and Park, Chiwoo and Gramacy, Robert B.",
      "chapter": "",
      "edition": "",
      "journal": "",
      "abstract": "Gaussian processes (GPs) furnish accurate nonlinear predictions with well-calibrated uncertainty. However, the typical GP setup has a built-in stationarity assumption, making it ill-suited for modeling data from processes with sudden changes, or \"jumps\" in the output variable. The \"jump GP\" (JGP) was developed for modeling data from such processes, combining local GPs and latent \"level\" variables under a joint inferential framework. But joint modeling can be fraught with difficulty. We aim to simplify by suggesting a more modular setup, eschewing joint inference but retaining the main JGP themes: (a) learning optimal neighborhood sizes that locally respect manifolds of discontinuity; and (b) a new cluster-based (latent) feature to capture regions of distinct output levels on both sides of the manifold. We show that each of (a) and (b) separately leads to dramatic improvements when modeling processes with jumps. In tandem (but without requiring joint inference) that benefit is compounded, as illustrated on real and synthetic benchmark examples from the recent literature.",
      "bibtexId": "flowers_modular_2025",
      "keywords": "Computer Science - Machine Learning, Statistics - Methodology",
      "booktitle": "",
      "entryType": "misc",
      "publisher": "arXiv",
      "categories": [
        "Other GP Litterature"
      ],
      "citationKey": "flowers_modular_2025",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@misc{flowers_modular_2025, \ttitle = {Modular {Jump} {Gaussian} {Processes}}, \turl = {http://arxiv.org/abs/2505.15557}, \tdoi = {10.48550/arXiv.2505.15557}, \tabstract = {Gaussian processes (GPs) furnish accurate nonlinear predictions with well-calibrated uncertainty. However, the typical GP setup has a built-in stationarity assumption, making it ill-suited for modeling data from processes with sudden changes, or \"jumps\" in the output variable. The \"jump GP\" (JGP) was developed for modeling data from such processes, combining local GPs and latent \"level\" variables under a joint inferential framework. But joint modeling can be fraught with difficulty. We aim to simplify by suggesting a more modular setup, eschewing joint inference but retaining the main JGP themes: (a) learning optimal neighborhood sizes that locally respect manifolds of discontinuity; and (b) a new cluster-based (latent) feature to capture regions of distinct output levels on both sides of the manifold. We show that each of (a) and (b) separately leads to dramatic improvements when modeling processes with jumps. In tandem (but without requiring joint inference) that benefit is compounded, as illustrated on real and synthetic benchmark examples from the recent literature.}, \turldate = {2025-10-06}, \tpublisher = {arXiv}, \tauthor = {Flowers, Anna R. and Franck, Christopher T. and Binois, Mickaël and Park, Chiwoo and Gramacy, Robert B.}, \tmonth = sep, \tyear = {2025}, \tnote = {arXiv:2505.15557}, \tkeywords = {Computer Science - Machine Learning, Statistics - Methodology}, }"
    },
    {
      "id": 27,
      "doi": "",
      "pdf": "",
      "url": "https://www.jstor.org/stable/2673557",
      "date": "2000-01-01",
      "isbn": "",
      "issn": "0006-3444",
      "link": "https://www.jstor.org/stable/2673557",
      "note": "Publisher: [Oxford University Press, Biometrika Trust]",
      "text": "We consider prediction and uncertainty analysis for complex computer codes which can be run at different levels of sophistication. In particular, we wish to improve efficiency by combining expensive runs of the most complex versions of the code with relatively cheap runs from one or more simpler approximations. A Bayesian approach is described in which prior beliefs about the codes are represented in terms of Gaussian processes. An example is presented using two versions of an oil reservoir simulator.",
      "year": "2000",
      "month": "",
      "pages": "1--13",
      "title": "Predicting the {Output",
      "number": "1",
      "school": "",
      "series": "",
      "volume": "87",
      "address": "",
      "authors": "Kennedy, M. C. and O'Hagan, A.",
      "chapter": "",
      "edition": "",
      "journal": "Biometrika",
      "abstract": "We consider prediction and uncertainty analysis for complex computer codes which can be run at different levels of sophistication. In particular, we wish to improve efficiency by combining expensive runs of the most complex versions of the code with relatively cheap runs from one or more simpler approximations. A Bayesian approach is described in which prior beliefs about the codes are represented in terms of Gaussian processes. An example is presented using two versions of an oil reservoir simulator.",
      "bibtexId": "kennedy_predicting_2000",
      "keywords": "",
      "booktitle": "",
      "entryType": "article",
      "publisher": "",
      "categories": [
        "MF-GP",
        "MF-ARGP"
      ],
      "citationKey": "kennedy_predicting_2000",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@article{kennedy_predicting_2000, \ttitle = {Predicting the {Output} from a {Complex} {Computer} {Code} {When} {Fast} {Approximations} {Are} {Available}}, \tvolume = {87}, \tissn = {0006-3444}, \turl = {https://www.jstor.org/stable/2673557}, \tabstract = {We consider prediction and uncertainty analysis for complex computer codes which can be run at different levels of sophistication. In particular, we wish to improve efficiency by combining expensive runs of the most complex versions of the code with relatively cheap runs from one or more simpler approximations. A Bayesian approach is described in which prior beliefs about the codes are represented in terms of Gaussian processes. An example is presented using two versions of an oil reservoir simulator.}, \tnumber = {1}, \turldate = {2025-10-06}, \tjournal = {Biometrika}, \tauthor = {Kennedy, M. C. and O'Hagan, A.}, \tyear = {2000}, \tnote = {Publisher: [Oxford University Press, Biometrika Trust]}, \tpages = {1--13}, }"
    },
    {
      "id": 28,
      "doi": "",
      "pdf": "http://proceedings.mlr.press/v31/damianou13a.pdf",
      "url": "https://proceedings.mlr.press/v31/damianou13a.html",
      "date": "2013-29 Apr--01 May-01",
      "isbn": "",
      "issn": "",
      "link": "https://proceedings.mlr.press/v31/damianou13a.html",
      "note": "",
      "text": "In this paper we introduce deep Gaussian process (GP) models. Deep GPs are a deep belief network based on Gaussian process mappings. The data is modeled as the output of a multivariate GP. The inputs to that Gaussian process are then governed by another GP. A single layer model is equivalent to a standard GP or the GP latent variable model (GP-LVM). We perform inference in the model by approximate variational marginalization. This results in a strict lower bound on the marginal likelihood of the model which we use for model selection (number of layers and nodes per layer). Deep belief networks are typically applied to relatively large data sets using stochastic gradient descent for optimization. Our fully Bayesian treatment allows for the application of deep models even when data is scarce. Model selection by our variational bound shows that a five layer hierarchy is justified even when modelling a digit data set containing only 150 examples.",
      "year": "2013",
      "month": "29 Apr--01 May",
      "pages": "207--215",
      "title": "Deep {G",
      "number": "",
      "school": "",
      "series": "Proceedings of Machine Learning Research",
      "volume": "31",
      "address": "Scottsdale, Arizona, USA",
      "authors": "Damianou, Andreas and Lawrence, Neil D.",
      "chapter": "",
      "edition": "",
      "journal": "",
      "abstract": "In this paper we introduce deep Gaussian process (GP) models. Deep GPs are a deep belief network based on Gaussian process mappings. The data is modeled as the output of a multivariate GP. The inputs to that Gaussian process are then governed by another GP. A single layer model is equivalent to a standard GP or the GP latent variable model (GP-LVM). We perform inference in the model by approximate variational marginalization. This results in a strict lower bound on the marginal likelihood of the model which we use for model selection (number of layers and nodes per layer). Deep belief networks are typically applied to relatively large data sets using stochastic gradient descent for optimization. Our fully Bayesian treatment allows for the application of deep models even when data is scarce. Model selection by our variational bound shows that a five layer hierarchy is justified even when modelling a digit data set containing only 150 examples.",
      "bibtexId": "pmlr-v31-damianou13a",
      "keywords": "",
      "booktitle": "Proceedings of the Sixteenth International Conference on Artificial Intelligence and Statistics",
      "entryType": "inproceedings",
      "publisher": "PMLR",
      "categories": [
        "Other GP Litterature"
      ],
      "citationKey": "pmlr-v31-damianou13a",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@InProceedings{pmlr-v31-damianou13a,   title = \t {Deep {G}aussian Processes},   author = \t {Damianou, Andreas and Lawrence, Neil D.},   booktitle = \t {Proceedings of the Sixteenth International Conference on Artificial Intelligence and Statistics},   pages = \t {207--215},   year = \t {2013},   editor = \t {Carvalho, Carlos M. and Ravikumar, Pradeep},   volume = \t {31},   series = \t {Proceedings of Machine Learning Research},   address = \t {Scottsdale, Arizona, USA},   month = \t {29 Apr--01 May},   publisher =    {PMLR},   pdf = \t {http://proceedings.mlr.press/v31/damianou13a.pdf},   url = \t {https://proceedings.mlr.press/v31/damianou13a.html},   abstract = \t {In this paper we introduce deep Gaussian process (GP) models. Deep GPs are a deep belief network based on Gaussian process mappings. The data is modeled as the output of a multivariate GP. The inputs to that Gaussian process are then governed by another GP. A single layer model is equivalent to a standard GP or the GP latent variable model (GP-LVM). We perform inference in the model by approximate variational marginalization. This results in a strict lower bound on the marginal likelihood of the model which we use for model selection (number of layers and nodes per layer). Deep belief networks are typically applied to relatively large data sets using stochastic gradient descent for optimization. Our fully Bayesian treatment allows for the application of deep models even when data is scarce. Model selection by our variational bound shows that a five layer hierarchy is justified even when modelling a digit data set containing only 150 examples.} }"
    },
    {
      "id": 29,
      "doi": "",
      "pdf": "",
      "url": "https://theses.fr/2015GREAM069",
      "date": "2015-01-01",
      "isbn": "",
      "issn": "",
      "link": "https://theses.fr/2015GREAM069",
      "note": "",
      "text": "Les simulations par ordinateur sont un outil de grande importance pour les mathématiciens appliqués et les ingénieurs. Elles sont devenues plus précises mais aussi plus compliquées. Tellement compliquées, que le temps de lancement par calcul est prohibitif. Donc, plusieurs aspects de ces simulations sont mal compris. Par exemple, souvent ces simulations dépendent des paramètres qu'ont une valeur inconnue.Un metamodèle est une reconstruction de la simulation. Il produit des réponses proches à celles de la simulation avec un temps de calcul très réduit. Avec ce metamodèle il est possible d'étudier certains aspects de la simulation. Il est construit avec peu de données et son objectif est de remplacer la simulation originale.Ce travail est concerné avec la construction des metamodèles dans un cadre particulier appelé multi-fidélité. En multi-fidélité, le metamodèle est construit à partir des données produites par une simulation objective et des données qu'ont une relation avec cette simulation. Ces données approximées peuvent être générés par des versions dégradées de la simulation ; par des anciennes versions qu'ont été largement étudiées ou par une autre simulation dans laquelle une partie de la description est simplifiée.En apprenant la différence entre les données il est possible d'incorporer l'information approximée et ce ci peut nous conduire vers un metamodèle amélioré. Deux approches pour atteindre ce but sont décrites dans ce manuscrit : la première est basée sur des modèles avec des processus gaussiens et la seconde sur une décomposition à base d'ondelettes. La première montre qu'en estimant la relation il est possible d'incorporer des données qui n'ont pas de valeur autrement. Dans la seconde, les données sont ajoutées de façon adaptative pour améliorer le metamodèle.L'objet de ce travail est d'améliorer notre compréhension sur comment incorporer des données approximées pour produire des metamodèles plus précis. Travailler avec un metamodèle multi-fidélité nous aide à comprendre en détail ces éléments. A la fin une image globale des parties qui forment ce metamodèle commence à s'esquisser : les relations et différences entres les données deviennent plus claires.",
      "year": "2015",
      "month": "",
      "pages": "",
      "title": "Utilisation de simulateurs multi-fidélité pour les études d'incertitudes dans les codes de caclul",
      "number": "",
      "school": "Université Grenoble Alpes (ComUE)",
      "series": "",
      "volume": "",
      "address": "",
      "authors": "Zertuche, Federico",
      "chapter": "",
      "edition": "",
      "journal": "",
      "abstract": "Les simulations par ordinateur sont un outil de grande importance pour les mathématiciens appliqués et les ingénieurs. Elles sont devenues plus précises mais aussi plus compliquées. Tellement compliquées, que le temps de lancement par calcul est prohibitif. Donc, plusieurs aspects de ces simulations sont mal compris. Par exemple, souvent ces simulations dépendent des paramètres qu'ont une valeur inconnue.Un metamodèle est une reconstruction de la simulation. Il produit des réponses proches à celles de la simulation avec un temps de calcul très réduit. Avec ce metamodèle il est possible d'étudier certains aspects de la simulation. Il est construit avec peu de données et son objectif est de remplacer la simulation originale.Ce travail est concerné avec la construction des metamodèles dans un cadre particulier appelé multi-fidélité. En multi-fidélité, le metamodèle est construit à partir des données produites par une simulation objective et des données qu'ont une relation avec cette simulation. Ces données approximées peuvent être générés par des versions dégradées de la simulation ; par des anciennes versions qu'ont été largement étudiées ou par une autre simulation dans laquelle une partie de la description est simplifiée.En apprenant la différence entre les données il est possible d'incorporer l'information approximée et ce ci peut nous conduire vers un metamodèle amélioré. Deux approches pour atteindre ce but sont décrites dans ce manuscrit : la première est basée sur des modèles avec des processus gaussiens et la seconde sur une décomposition à base d'ondelettes. La première montre qu'en estimant la relation il est possible d'incorporer des données qui n'ont pas de valeur autrement. Dans la seconde, les données sont ajoutées de façon adaptative pour améliorer le metamodèle.L'objet de ce travail est d'améliorer notre compréhension sur comment incorporer des données approximées pour produire des metamodèles plus précis. Travailler avec un metamodèle multi-fidélité nous aide à comprendre en détail ces éléments. A la fin une image globale des parties qui forment ce metamodèle commence à s'esquisser : les relations et différences entres les données deviennent plus claires.",
      "bibtexId": "zertuche_utilisation_2015",
      "keywords": "",
      "booktitle": "",
      "entryType": "phdthesis",
      "publisher": "",
      "categories": [
        "MF-GP",
        "Application MF-GP"
      ],
      "citationKey": "zertuche_utilisation_2015",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@phdthesis{zertuche_utilisation_2015, \ttype = {thesis}, \ttitle = {Utilisation de simulateurs multi-fidélité pour les études d'incertitudes dans les codes de caclul}, \turl = {https://theses.fr/2015GREAM069}, \tabstract = {Les simulations par ordinateur sont un outil de grande importance pour les mathématiciens appliqués et les ingénieurs. Elles sont devenues plus précises mais aussi plus compliquées. Tellement compliquées, que le temps de lancement par calcul est prohibitif. Donc, plusieurs aspects de ces simulations sont mal compris. Par exemple, souvent ces simulations dépendent des paramètres qu'ont une valeur inconnue.Un metamodèle est une reconstruction de la simulation. Il produit des réponses proches à celles de la simulation avec un temps de calcul très réduit. Avec ce metamodèle il est possible d'étudier certains aspects de la simulation. Il est construit avec peu de données et son objectif est de remplacer la simulation originale.Ce travail est concerné avec la construction des metamodèles dans un cadre particulier appelé multi-fidélité. En multi-fidélité, le metamodèle est construit à partir des données produites par une simulation objective et des données qu'ont une relation avec cette simulation. Ces données approximées peuvent être générés par des versions dégradées de la simulation ; par des anciennes versions qu'ont été largement étudiées ou par une autre simulation dans laquelle une partie de la description est simplifiée.En apprenant la différence entre les données il est possible d'incorporer l'information approximée et ce ci peut nous conduire vers un metamodèle amélioré. Deux approches pour atteindre ce but sont décrites dans ce manuscrit : la première est basée sur des modèles avec des processus gaussiens et la seconde sur une décomposition à base d'ondelettes. La première montre qu'en estimant la relation il est possible d'incorporer des données qui n'ont pas de valeur autrement. Dans la seconde, les données sont ajoutées de façon adaptative pour améliorer le metamodèle.L'objet de ce travail est d'améliorer notre compréhension sur comment incorporer des données approximées pour produire des metamodèles plus précis. Travailler avec un metamodèle multi-fidélité nous aide à comprendre en détail ces éléments. A la fin une image globale des parties qui forment ce metamodèle commence à s'esquisser : les relations et différences entres les données deviennent plus claires.}, \tlanguage = {fr}, \turldate = {2025-10-22}, \tschool = {Université Grenoble Alpes (ComUE)}, \tauthor = {Zertuche, Federico}, \tmonth = aug, \tyear = {2015}, }"
    },
    {
      "id": 30,
      "doi": "",
      "pdf": "",
      "url": "https://pastel.hal.science/tel-01924714",
      "date": "2018-01-01",
      "isbn": "",
      "issn": "",
      "link": "https://pastel.hal.science/tel-01924714",
      "note": "",
      "text": "",
      "year": "2018",
      "month": "",
      "pages": "",
      "title": "Méthodes avancées d'optimisation par méta-modèles – {Applicationà",
      "number": "",
      "school": "École Nationale Supérieure des Arts et Métiers",
      "series": "",
      "volume": "",
      "address": "",
      "authors": "Sacher, Matthieu",
      "chapter": "",
      "edition": "",
      "journal": "",
      "abstract": "",
      "bibtexId": "sacher_methodes_2018",
      "keywords": "Classification, Fluid-Structure interaction, Gaussian process, Global optimization, Interaction fluide-Structure, Multi-Fidelity, Multi-Fidélité, Méta-Modèles, Optimisation globale, Processus Gaussien, Surrogate models",
      "booktitle": "",
      "entryType": "phdthesis",
      "publisher": "",
      "categories": [
        "MF-GP",
        "Application MF-GP"
      ],
      "citationKey": "sacher_methodes_2018",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@phdthesis{sacher_methodes_2018, \ttype = {Theses}, \ttitle = {Méthodes avancées d'optimisation par méta-modèles – {Applicationà} la performance des voiliers de compétition}, \turl = {https://pastel.hal.science/tel-01924714}, \tschool = {École Nationale Supérieure des Arts et Métiers}, \tauthor = {Sacher, Matthieu}, \tmonth = sep, \tyear = {2018}, \tkeywords = {Classification, Fluid-Structure interaction, Gaussian process, Global optimization, Interaction fluide-Structure, Multi-Fidelity, Multi-Fidélité, Méta-Modèles, Optimisation globale, Processus Gaussien, Surrogate models}, }"
    },
    {
      "id": 31,
      "doi": "",
      "pdf": "https://theses.hal.science/tel-00866770v2/file/manuscrit.pdf",
      "url": "https://theses.hal.science/tel-00866770",
      "date": "2013-01-01",
      "isbn": "",
      "issn": "",
      "link": "https://theses.hal.science/tel-00866770",
      "note": "",
      "text": "",
      "year": "2013",
      "month": "",
      "pages": "",
      "title": "{Multi-fidelity Gaussian process regression for computer experiments",
      "number": "",
      "school": "{Universit{\\'e",
      "series": "",
      "volume": "",
      "address": "",
      "authors": "Le Gratiet, Loic",
      "chapter": "",
      "edition": "",
      "journal": "",
      "abstract": "",
      "bibtexId": "legratiet:tel-00866770",
      "keywords": "Multi-fidelity computer codes ; Gaussian process regression ; Co-kriging ; Sequential design ; Sensitivity analysis ; Learning curve",
      "booktitle": "",
      "entryType": "phdthesis",
      "publisher": "",
      "categories": [
        "MF-ARGP",
        "MF-GP"
      ],
      "citationKey": "legratiet:tel-00866770",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@phdthesis{legratiet:tel-00866770,   TITLE = {{Multi-fidelity Gaussian process regression for computer experiments}},   AUTHOR = {Le Gratiet, Loic},   URL = {https://theses.hal.science/tel-00866770},   SCHOOL = {{Universit{\\'e} Paris-Diderot - Paris VII}},   YEAR = {2013},   MONTH = Oct,   KEYWORDS = {Multi-fidelity computer codes ; Gaussian process regression ; Co-kriging ; Sequential design ; Sensitivity analysis ; Learning curve},   TYPE = {Theses},   PDF = {https://theses.hal.science/tel-00866770v2/file/manuscrit.pdf},   HAL_ID = {tel-00866770},   HAL_VERSION = {v2}, }"
    },
    {
      "id": 32,
      "doi": "10.48550/arXiv.2111.11223",
      "pdf": "",
      "url": "http://arxiv.org/abs/2111.11223",
      "date": "2022-01-01",
      "isbn": "",
      "issn": "",
      "link": "http://arxiv.org/abs/2111.11223",
      "note": "arXiv:2111.11223",
      "text": "Bayesian optimization is a powerful paradigm to optimize black-box functions based on scarce and noisy data. Its data efficiency can be further improved by transfer learning from related tasks. While recent transfer models meta-learn a prior based on large amount of data, in the low-data regime methods that exploit the closed-form posterior of Gaussian processes (GPs) have an advantage. In this setting, several analytically tractable transfer-model posteriors have been proposed, but the relative advantages of these methods are not well understood. In this paper, we provide a unified view on hierarchical GP models for transfer learning, which allows us to analyze the relationship between methods. As part of the analysis, we develop a novel closed-form boosted GP transfer model that fits between existing approaches in terms of complexity. We evaluate the performance of the different approaches in large-scale experiments and highlight strengths and weaknesses of the different transfer-learning methods.",
      "year": "2022",
      "month": "",
      "pages": "",
      "title": "Transfer {Learning",
      "number": "",
      "school": "",
      "series": "",
      "volume": "",
      "address": "",
      "authors": "Tighineanu, Petru and Skubch, Kathrin and Baireuther, Paul and Reiss, Attila and Berkenkamp, Felix and Vinogradska, Julia",
      "chapter": "",
      "edition": "",
      "journal": "",
      "abstract": "Bayesian optimization is a powerful paradigm to optimize black-box functions based on scarce and noisy data. Its data efficiency can be further improved by transfer learning from related tasks. While recent transfer models meta-learn a prior based on large amount of data, in the low-data regime methods that exploit the closed-form posterior of Gaussian processes (GPs) have an advantage. In this setting, several analytically tractable transfer-model posteriors have been proposed, but the relative advantages of these methods are not well understood. In this paper, we provide a unified view on hierarchical GP models for transfer learning, which allows us to analyze the relationship between methods. As part of the analysis, we develop a novel closed-form boosted GP transfer model that fits between existing approaches in terms of complexity. We evaluate the performance of the different approaches in large-scale experiments and highlight strengths and weaknesses of the different transfer-learning methods.",
      "bibtexId": "tighineanu_transfer_2022",
      "keywords": "Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning",
      "booktitle": "",
      "entryType": "misc",
      "publisher": "arXiv",
      "categories": [
        "Other GP Litterature",
        "BO-GP"
      ],
      "citationKey": "tighineanu_transfer_2022",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@misc{tighineanu_transfer_2022, \ttitle = {Transfer {Learning} with {Gaussian} {Processes} for {Bayesian} {Optimization}}, \turl = {http://arxiv.org/abs/2111.11223}, \tdoi = {10.48550/arXiv.2111.11223}, \tabstract = {Bayesian optimization is a powerful paradigm to optimize black-box functions based on scarce and noisy data. Its data efficiency can be further improved by transfer learning from related tasks. While recent transfer models meta-learn a prior based on large amount of data, in the low-data regime methods that exploit the closed-form posterior of Gaussian processes (GPs) have an advantage. In this setting, several analytically tractable transfer-model posteriors have been proposed, but the relative advantages of these methods are not well understood. In this paper, we provide a unified view on hierarchical GP models for transfer learning, which allows us to analyze the relationship between methods. As part of the analysis, we develop a novel closed-form boosted GP transfer model that fits between existing approaches in terms of complexity. We evaluate the performance of the different approaches in large-scale experiments and highlight strengths and weaknesses of the different transfer-learning methods.}, \turldate = {2025-10-29}, \tpublisher = {arXiv}, \tauthor = {Tighineanu, Petru and Skubch, Kathrin and Baireuther, Paul and Reiss, Attila and Berkenkamp, Felix and Vinogradska, Julia}, \tmonth = mar, \tyear = {2022}, \tnote = {arXiv:2111.11223}, \tkeywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning}, }"
    },
    {
      "id": 33,
      "doi": "10.48550/arXiv.2112.15311",
      "pdf": "",
      "url": "http://arxiv.org/abs/2112.15311",
      "date": "2021-01-01",
      "isbn": "",
      "issn": "",
      "link": "http://arxiv.org/abs/2112.15311",
      "note": "arXiv:2112.15311",
      "text": "We consider Bayesian optimization of the output of a network of functions, where each function takes as input the output of its parent nodes, and where the network takes significant time to evaluate. Such problems arise, for example, in reinforcement learning, engineering design, and manufacturing. While the standard Bayesian optimization approach observes only the final output, our approach delivers greater query efficiency by leveraging information that the former ignores: intermediate output within the network. This is achieved by modeling the nodes of the network using Gaussian processes and choosing the points to evaluate using, as our acquisition function, the expected improvement computed with respect to the implied posterior on the objective. Although the non-Gaussian nature of this posterior prevents computing our acquisition function in closed form, we show that it can be efficiently maximized via sample average approximation. In addition, we prove that our method is asymptotically consistent, meaning that it finds a globally optimal solution as the number of evaluations grows to infinity, thus generalizing previously known convergence results for the expected improvement. Notably, this holds even though our method might not evaluate the domain densely, instead leveraging problem structure to leave regions unexplored. Finally, we show that our approach dramatically outperforms standard Bayesian optimization methods in several synthetic and real-world problems.",
      "year": "2021",
      "month": "",
      "pages": "",
      "title": "Bayesian {Optimization",
      "number": "",
      "school": "",
      "series": "",
      "volume": "",
      "address": "",
      "authors": "Astudillo, Raul and Frazier, Peter I.",
      "chapter": "",
      "edition": "",
      "journal": "",
      "abstract": "We consider Bayesian optimization of the output of a network of functions, where each function takes as input the output of its parent nodes, and where the network takes significant time to evaluate. Such problems arise, for example, in reinforcement learning, engineering design, and manufacturing. While the standard Bayesian optimization approach observes only the final output, our approach delivers greater query efficiency by leveraging information that the former ignores: intermediate output within the network. This is achieved by modeling the nodes of the network using Gaussian processes and choosing the points to evaluate using, as our acquisition function, the expected improvement computed with respect to the implied posterior on the objective. Although the non-Gaussian nature of this posterior prevents computing our acquisition function in closed form, we show that it can be efficiently maximized via sample average approximation. In addition, we prove that our method is asymptotically consistent, meaning that it finds a globally optimal solution as the number of evaluations grows to infinity, thus generalizing previously known convergence results for the expected improvement. Notably, this holds even though our method might not evaluate the domain densely, instead leveraging problem structure to leave regions unexplored. Finally, we show that our approach dramatically outperforms standard Bayesian optimization methods in several synthetic and real-world problems.",
      "bibtexId": "astudillo_bayesian_2021",
      "keywords": "Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning",
      "booktitle": "",
      "entryType": "misc",
      "publisher": "arXiv",
      "categories": [
        "Other GP Litterature",
        "BO-GP"
      ],
      "citationKey": "astudillo_bayesian_2021",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@misc{astudillo_bayesian_2021, \ttitle = {Bayesian {Optimization} of {Function} {Networks}}, \turl = {http://arxiv.org/abs/2112.15311}, \tdoi = {10.48550/arXiv.2112.15311}, \tabstract = {We consider Bayesian optimization of the output of a network of functions, where each function takes as input the output of its parent nodes, and where the network takes significant time to evaluate. Such problems arise, for example, in reinforcement learning, engineering design, and manufacturing. While the standard Bayesian optimization approach observes only the final output, our approach delivers greater query efficiency by leveraging information that the former ignores: intermediate output within the network. This is achieved by modeling the nodes of the network using Gaussian processes and choosing the points to evaluate using, as our acquisition function, the expected improvement computed with respect to the implied posterior on the objective. Although the non-Gaussian nature of this posterior prevents computing our acquisition function in closed form, we show that it can be efficiently maximized via sample average approximation. In addition, we prove that our method is asymptotically consistent, meaning that it finds a globally optimal solution as the number of evaluations grows to infinity, thus generalizing previously known convergence results for the expected improvement. Notably, this holds even though our method might not evaluate the domain densely, instead leveraging problem structure to leave regions unexplored. Finally, we show that our approach dramatically outperforms standard Bayesian optimization methods in several synthetic and real-world problems.}, \turldate = {2025-10-29}, \tpublisher = {arXiv}, \tauthor = {Astudillo, Raul and Frazier, Peter I.}, \tmonth = dec, \tyear = {2021}, \tnote = {arXiv:2112.15311}, \tkeywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning}, }"
    },
    {
      "id": 34,
      "doi": "10.48550/arXiv.1603.00389",
      "pdf": "",
      "url": "http://arxiv.org/abs/1603.00389",
      "date": "2016-01-01",
      "isbn": "",
      "issn": "",
      "link": "http://arxiv.org/abs/1603.00389",
      "note": "arXiv:1603.00389",
      "text": "We consider Bayesian optimization of an expensive-to-evaluate black-box objective function, where we also have access to cheaper approximations of the objective. In general, such approximations arise in applications such as reinforcement learning, engineering, and the natural sciences, and are subject to an inherent, unknown bias. This model discrepancy is caused by an inadequate internal model that deviates from reality and can vary over the domain, making the utilization of these approximations a non-trivial task. We present a novel algorithm that provides a rigorous mathematical treatment of the uncertainties arising from model discrepancies and noisy observations. Its optimization decisions rely on a value of information analysis that extends the Knowledge Gradient factor to the setting of multiple information sources that vary in cost: each sampling decision maximizes the predicted benefit per unit cost. We conduct an experimental evaluation that demonstrates that the method consistently outperforms other state-of-the-art techniques: it finds designs of considerably higher objective value and additionally inflicts less cost in the exploration process.",
      "year": "2016",
      "month": "",
      "pages": "",
      "title": "Multi-{Information",
      "number": "",
      "school": "",
      "series": "",
      "volume": "",
      "address": "",
      "authors": "Poloczek, Matthias and Wang, Jialei and Frazier, Peter I.",
      "chapter": "",
      "edition": "",
      "journal": "",
      "abstract": "We consider Bayesian optimization of an expensive-to-evaluate black-box objective function, where we also have access to cheaper approximations of the objective. In general, such approximations arise in applications such as reinforcement learning, engineering, and the natural sciences, and are subject to an inherent, unknown bias. This model discrepancy is caused by an inadequate internal model that deviates from reality and can vary over the domain, making the utilization of these approximations a non-trivial task. We present a novel algorithm that provides a rigorous mathematical treatment of the uncertainties arising from model discrepancies and noisy observations. Its optimization decisions rely on a value of information analysis that extends the Knowledge Gradient factor to the setting of multiple information sources that vary in cost: each sampling decision maximizes the predicted benefit per unit cost. We conduct an experimental evaluation that demonstrates that the method consistently outperforms other state-of-the-art techniques: it finds designs of considerably higher objective value and additionally inflicts less cost in the exploration process.",
      "bibtexId": "poloczek_multi-information_2016",
      "keywords": "Statistics - Machine Learning",
      "booktitle": "",
      "entryType": "misc",
      "publisher": "arXiv",
      "categories": [
        "MF-GP",
        "Other MF-GP"
      ],
      "citationKey": "poloczek_multi-information_2016",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@misc{poloczek_multi-information_2016, \ttitle = {Multi-{Information} {Source} {Optimization}}, \turl = {http://arxiv.org/abs/1603.00389}, \tdoi = {10.48550/arXiv.1603.00389}, \tabstract = {We consider Bayesian optimization of an expensive-to-evaluate black-box objective function, where we also have access to cheaper approximations of the objective. In general, such approximations arise in applications such as reinforcement learning, engineering, and the natural sciences, and are subject to an inherent, unknown bias. This model discrepancy is caused by an inadequate internal model that deviates from reality and can vary over the domain, making the utilization of these approximations a non-trivial task. We present a novel algorithm that provides a rigorous mathematical treatment of the uncertainties arising from model discrepancies and noisy observations. Its optimization decisions rely on a value of information analysis that extends the Knowledge Gradient factor to the setting of multiple information sources that vary in cost: each sampling decision maximizes the predicted benefit per unit cost. We conduct an experimental evaluation that demonstrates that the method consistently outperforms other state-of-the-art techniques: it finds designs of considerably higher objective value and additionally inflicts less cost in the exploration process.}, \turldate = {2025-10-29}, \tpublisher = {arXiv}, \tauthor = {Poloczek, Matthias and Wang, Jialei and Frazier, Peter I.}, \tmonth = nov, \tyear = {2016}, \tnote = {arXiv:1603.00389}, \tkeywords = {Statistics - Machine Learning}, }"
    },
    {
      "id": 35,
      "doi": "10.48550/arXiv.2209.13748",
      "pdf": "",
      "url": "http://arxiv.org/abs/2209.13748",
      "date": "2023-01-01",
      "isbn": "",
      "issn": "",
      "link": "http://arxiv.org/abs/2209.13748",
      "note": "arXiv:2209.13748",
      "text": "In an era where scientific experimentation is often costly, multi-fidelity emulation provides a powerful tool for predictive scientific computing. While there has been notable work on multi-fidelity modeling, existing models do not incorporate an important \"conglomerate\" property of multi-fidelity simulators, where the accuracies of different simulator components are controlled by different fidelity parameters. Such conglomerate simulators are widely encountered in complex nuclear physics and astrophysics applications. We thus propose a new CONglomerate multi-FIdelity Gaussian process (CONFIG) model, which embeds this conglomerate structure within a novel non-stationary covariance function. We show that the proposed CONFIG model can capture prior knowledge on the numerical convergence of conglomerate simulators, which allows for cost-efficient emulation of multi-fidelity systems. We demonstrate the improved predictive performance of CONFIG over state-of-the-art models in a suite of numerical experiments and two applications, the first for emulation of cantilever beam deflection and the second for emulating the evolution of the quark-gluon plasma, which was theorized to have filled the Universe shortly after the Big Bang.",
      "year": "2023",
      "month": "",
      "pages": "",
      "title": "Conglomerate {Multi",
      "number": "",
      "school": "",
      "series": "",
      "volume": "",
      "address": "",
      "authors": "Ji, Yi and Yuchi, Henry Shaowu and Soeder, Derek and Paquet, J.-F. and Bass, Steffen A. and Joseph, V. Roshan and Wu, C. F. Jeff and Mak, Simon",
      "chapter": "",
      "edition": "",
      "journal": "",
      "abstract": "In an era where scientific experimentation is often costly, multi-fidelity emulation provides a powerful tool for predictive scientific computing. While there has been notable work on multi-fidelity modeling, existing models do not incorporate an important \"conglomerate\" property of multi-fidelity simulators, where the accuracies of different simulator components are controlled by different fidelity parameters. Such conglomerate simulators are widely encountered in complex nuclear physics and astrophysics applications. We thus propose a new CONglomerate multi-FIdelity Gaussian process (CONFIG) model, which embeds this conglomerate structure within a novel non-stationary covariance function. We show that the proposed CONFIG model can capture prior knowledge on the numerical convergence of conglomerate simulators, which allows for cost-efficient emulation of multi-fidelity systems. We demonstrate the improved predictive performance of CONFIG over state-of-the-art models in a suite of numerical experiments and two applications, the first for emulation of cantilever beam deflection and the second for emulating the evolution of the quark-gluon plasma, which was theorized to have filled the Universe shortly after the Big Bang.",
      "bibtexId": "ji_conglomerate_2023",
      "keywords": "Statistics - Methodology",
      "booktitle": "",
      "entryType": "misc",
      "publisher": "arXiv",
      "categories": [
        "MF-GP",
        "Other MF-GP"
      ],
      "citationKey": "ji_conglomerate_2023",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@misc{ji_conglomerate_2023, \ttitle = {Conglomerate {Multi}-{Fidelity} {Gaussian} {Process} {Modeling}, with {Application} to {Heavy}-{Ion} {Collisions}}, \turl = {http://arxiv.org/abs/2209.13748}, \tdoi = {10.48550/arXiv.2209.13748}, \tabstract = {In an era where scientific experimentation is often costly, multi-fidelity emulation provides a powerful tool for predictive scientific computing. While there has been notable work on multi-fidelity modeling, existing models do not incorporate an important \"conglomerate\" property of multi-fidelity simulators, where the accuracies of different simulator components are controlled by different fidelity parameters. Such conglomerate simulators are widely encountered in complex nuclear physics and astrophysics applications. We thus propose a new CONglomerate multi-FIdelity Gaussian process (CONFIG) model, which embeds this conglomerate structure within a novel non-stationary covariance function. We show that the proposed CONFIG model can capture prior knowledge on the numerical convergence of conglomerate simulators, which allows for cost-efficient emulation of multi-fidelity systems. We demonstrate the improved predictive performance of CONFIG over state-of-the-art models in a suite of numerical experiments and two applications, the first for emulation of cantilever beam deflection and the second for emulating the evolution of the quark-gluon plasma, which was theorized to have filled the Universe shortly after the Big Bang.}, \turldate = {2025-10-29}, \tpublisher = {arXiv}, \tauthor = {Ji, Yi and Yuchi, Henry Shaowu and Soeder, Derek and Paquet, J.-F. and Bass, Steffen A. and Joseph, V. Roshan and Wu, C. F. Jeff and Mak, Simon}, \tmonth = sep, \tyear = {2023}, \tnote = {arXiv:2209.13748}, \tkeywords = {Statistics - Methodology}, }"
    },
    {
      "id": 36,
      "doi": "10.2514/1.J059803",
      "pdf": "",
      "url": "https://arc.aiaa.org/doi/10.2514/1.J059803",
      "date": "2021-01-01",
      "isbn": "",
      "issn": "0001-1452, 1533-385X",
      "link": "https://arc.aiaa.org/doi/10.2514/1.J059803",
      "note": "",
      "text": "",
      "year": "2021",
      "month": "",
      "pages": "1964--1974",
      "title": "Bayesian {Optimization",
      "number": "6",
      "school": "",
      "series": "",
      "volume": "59",
      "address": "",
      "authors": "Khatamsaz, Danial and Peddareddygari, Lalith and Friedman, Samuel and Allaire, Douglas",
      "chapter": "",
      "edition": "",
      "journal": "AIAA Journal",
      "abstract": "",
      "bibtexId": "khatamsaz_bayesian_2021",
      "keywords": "",
      "booktitle": "",
      "entryType": "article",
      "publisher": "",
      "categories": [
        "MF-GP",
        "MF-DGP"
      ],
      "citationKey": "khatamsaz_bayesian_2021",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@article{khatamsaz_bayesian_2021, \ttitle = {Bayesian {Optimization} of {Multiobjective} {Functions} {Using} {Multiple} {Information} {Sources}}, \tvolume = {59}, \tissn = {0001-1452, 1533-385X}, \turl = {https://arc.aiaa.org/doi/10.2514/1.J059803}, \tdoi = {10.2514/1.J059803}, \tlanguage = {en}, \tnumber = {6}, \turldate = {2025-10-29}, \tjournal = {AIAA Journal}, \tauthor = {Khatamsaz, Danial and Peddareddygari, Lalith and Friedman, Samuel and Allaire, Douglas}, \tmonth = jun, \tyear = {2021}, \tpages = {1964--1974}, }"
    },
    {
      "id": 37,
      "doi": "10.48550/arXiv.2402.03809",
      "pdf": "",
      "url": "http://arxiv.org/abs/2402.03809",
      "date": "2024-01-01",
      "isbn": "",
      "issn": "",
      "link": "http://arxiv.org/abs/2402.03809",
      "note": "arXiv:2402.03809",
      "text": "Gaussian processes are a widely embraced technique for regression and classification due to their good prediction accuracy, analytical tractability and built-in capabilities for uncertainty quantification. However, they suffer from the curse of dimensionality whenever the number of variables increases. This challenge is generally addressed by assuming additional structure in theproblem, the preferred options being either additivity or low intrinsic dimensionality. Our contribution for high-dimensional Gaussian process modeling is to combine them with a multi-fidelity strategy, showcasing the advantages through experiments on synthetic functions and datasets.",
      "year": "2024",
      "month": "",
      "pages": "",
      "title": "Combining additivity and active subspaces for high-dimensional {Gaussian",
      "number": "",
      "school": "",
      "series": "",
      "volume": "",
      "address": "",
      "authors": "Binois, Mickael and Picheny, Victor",
      "chapter": "",
      "edition": "",
      "journal": "",
      "abstract": "Gaussian processes are a widely embraced technique for regression and classification due to their good prediction accuracy, analytical tractability and built-in capabilities for uncertainty quantification. However, they suffer from the curse of dimensionality whenever the number of variables increases. This challenge is generally addressed by assuming additional structure in theproblem, the preferred options being either additivity or low intrinsic dimensionality. Our contribution for high-dimensional Gaussian process modeling is to combine them with a multi-fidelity strategy, showcasing the advantages through experiments on synthetic functions and datasets.",
      "bibtexId": "binois_combining_2024",
      "keywords": "Mathematics - Optimization and Control, Statistics - Machine Learning",
      "booktitle": "",
      "entryType": "misc",
      "publisher": "arXiv",
      "categories": [
        "MF-GP",
        "Application MF-GP"
      ],
      "citationKey": "binois_combining_2024",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@misc{binois_combining_2024, \ttitle = {Combining additivity and active subspaces for high-dimensional {Gaussian} process modeling}, \turl = {http://arxiv.org/abs/2402.03809}, \tdoi = {10.48550/arXiv.2402.03809}, \tabstract = {Gaussian processes are a widely embraced technique for regression and classification due to their good prediction accuracy, analytical tractability and built-in capabilities for uncertainty quantification. However, they suffer from the curse of dimensionality whenever the number of variables increases. This challenge is generally addressed by assuming additional structure in theproblem, the preferred options being either additivity or low intrinsic dimensionality. Our contribution for high-dimensional Gaussian process modeling is to combine them with a multi-fidelity strategy, showcasing the advantages through experiments on synthetic functions and datasets.}, \turldate = {2025-10-29}, \tpublisher = {arXiv}, \tauthor = {Binois, Mickael and Picheny, Victor}, \tmonth = feb, \tyear = {2024}, \tnote = {arXiv:2402.03809}, \tkeywords = {Mathematics - Optimization and Control, Statistics - Machine Learning}, }"
    },
    {
      "id": 38,
      "doi": "10.1016/j.ress.2024.110094",
      "pdf": "",
      "isbn": "",
      "issn": "",
      "link": "https://doi.org/10.1016/j.ress.2024.110094",
      "note": "",
      "text": "",
      "year": "2024",
      "pages": "110094",
      "title": "Probabilistic surrogate modeling by Gaussian process: A review on recent insights in estimation and validation",
      "number": "",
      "volume": "247",
      "authors": "Amandine Marrel, Bertrand Iooss",
      "journal": "Reliability Engineering &amp; System Safety",
      "abstract": "",
      "bibtexId": "marreliooss2024",
      "entryType": "article",
      "publisher": "Elsevier BV",
      "categories": [
        "Other GP Litterature",
        "GP Hyperparameters"
      ]
    },
    {
      "id": 39,
      "doi": "10.1016/j.ress.2024.110120",
      "pdf": "",
      "date": "2024-01-01",
      "isbn": "",
      "issn": "09518320",
      "link": "https://linkinghub.elsevier.com/retrieve/pii/S0951832024001947",
      "note": "",
      "text": "",
      "year": "2024",
      "pages": "110120",
      "title": "Probabilistic surrogate modeling by {Gaussian} process: {A} new estimation algorithm for more robust prediction",
      "number": "",
      "volume": "247",
      "authors": "Marrel, Amandine and Iooss, Bertrand",
      "journal": "Reliability Engineering \\& System Safety",
      "abstract": "",
      "bibtexId": "marrel_probabilistic_2024",
      "entryType": "article",
      "publisher": "",
      "categories": [
        "Other GP Litterature",
        "GP Hyperparameters"
      ],
      "citationKey": "marrel_probabilistic_2024",
      "originalBibTeX": "@article{marrel_probabilistic_2024, \ttitle = {Probabilistic surrogate modeling by {Gaussian} process: {A} new estimation algorithm for more robust prediction}, \tvolume = {247}, \tissn = {09518320}, \tshorttitle = {Probabilistic surrogate modeling by {Gaussian} process}, \turl = {https://linkinghub.elsevier.com/retrieve/pii/S0951832024001947}, \tdoi = {10.1016/j.ress.2024.110120}, \tlanguage = {en}, \turldate = {2025-10-30}, \tjournal = {Reliability Engineering \\& System Safety}, \tauthor = {Marrel, Amandine and Iooss, Bertrand}, \tmonth = jul, \tyear = {2024}, \tpages = {110120}, }"
    },
    {
      "id": 40,
      "doi": "",
      "pdf": "https://theses.hal.science/tel-03925818v1/file/2022UPASG063_PETIT_archivage.pdf",
      "date": "2022-01-01",
      "isbn": "",
      "issn": "",
      "link": "https://theses.hal.science/tel-03925818",
      "note": "",
      "text": "",
      "year": "2022",
      "pages": "",
      "title": "{Improved Gaussian process modeling : Application to Bayesian optimization}",
      "number": "2022UPASG063",
      "school": "{Universit{\\'e} Paris-Saclay}",
      "volume": "",
      "authors": "Petit, S{\\'e}bastien",
      "journal": "",
      "abstract": "",
      "bibtexId": "petit:tel-03925818",
      "keywords": "Model selection ; Optimization ; Kernel methods ; Bayesian methods ; Gaussian processes ; Optimisation ; M{\\'e}thodes {\\`a} noyaux ; Choix de mod{\\`e}le ; M{\\'e}thodes bay{\\'e}siennes ; Processus gaussiens",
      "entryType": "phdthesis",
      "publisher": "",
      "categories": [
        "Other GP Litterature",
        "GP Hyperparameters"
      ],
      "citationKey": "petit:tel-03925818",
      "originalBibTeX": "@phdthesis{petit:tel-03925818,   TITLE = {{Improved Gaussian process modeling : Application to Bayesian optimization}},   AUTHOR = {Petit, S{\\'e}bastien},   URL = {https://theses.hal.science/tel-03925818},   NUMBER = {2022UPASG063},   SCHOOL = {{Universit{\\'e} Paris-Saclay}},   YEAR = {2022},   MONTH = Sep,   KEYWORDS = {Model selection ; Optimization ; Kernel methods ; Bayesian methods ; Gaussian processes ; Optimisation ; M{\\'e}thodes {\\`a} noyaux ; Choix de mod{\\`e}le ; M{\\'e}thodes bay{\\'e}siennes ; Processus gaussiens},   TYPE = {Theses},   PDF = {https://theses.hal.science/tel-03925818v1/file/2022UPASG063_PETIT_archivage.pdf},   HAL_ID = {tel-03925818},   HAL_VERSION = {v1}, }"
    },
    {
      "id": 44,
      "doi": "10.1287/mnsc.26.1.18",
      "pdf": "",
      "isbn": "",
      "issn": "",
      "link": "https://doi.org/10.1287/mnsc.26.1.18",
      "note": "",
      "text": "",
      "year": "1980",
      "pages": "18-27",
      "title": "A Coverage Function for Interval Estimators of Simulation Response",
      "number": "",
      "volume": "26",
      "authors": "Lee W. Schruben",
      "journal": "Management Science",
      "abstract": "",
      "bibtexId": "schruben1980",
      "entryType": "article",
      "publisher": "Institute for Operations Research and the Management Sciences (INFORMS)",
      "categories": [
        "Other GP Litterature",
        "GP Hyperparameters"
      ]
    },
    {
      "id": 45,
      "doi": "",
      "pdf": "http://arxiv.org/pdf/1210.0686v3",
      "isbn": "",
      "issn": "",
      "link": "http://arxiv.org/abs/1210.0686v3",
      "note": "",
      "text": "",
      "year": "2012",
      "pages": "",
      "title": "Recursive co-kriging model for Design of Computer experiments with multiple levels of fidelity with an application to hydrodynamic",
      "number": "",
      "volume": "",
      "authors": "Loic Le Gratiet",
      "journal": "arXiv preprint",
      "abstract": "",
      "bibtexId": "gratiet2012",
      "entryType": "article",
      "publisher": "",
      "categories": [
        "MF-GP",
        "MF-ARGP"
      ]
    },
    {
      "id": 46,
      "doi": "https://doi.org/10.1016/j.csda.2022.107597",
      "pdf": "",
      "date": "2023-01-01",
      "isbn": "",
      "issn": "0167-9473",
      "link": "https://www.sciencedirect.com/science/article/pii/S0167947322001773",
      "note": "",
      "text": "Probabilistic regression models typically use the Maximum Likelihood Estimation or Cross-Validation to fit parameters. These methods can give an advantage to the solutions that fit observations on average, but they do not pay attention to the coverage and the width of Prediction Intervals. A robust two-step approach is used to address the problem of adjusting and calibrating Prediction Intervals for Gaussian Processes Regression. First, the covariance hyperparameters are determined by a standard Cross-Validation or Maximum Likelihood Estimation method. A Leave-One-Out Coverage Probability is introduced as a metric to adjust the covariance hyperparameters and assess the optimal type II Coverage Probability to a nominal level. Then a relaxation method is applied to choose the hyperparameters that minimize the Wasserstein distance between the Gaussian distribution with the initial hyperparameters (obtained by Cross-Validation or Maximum Likelihood Estimation) and the proposed Gaussian distribution with the hyperparameters that achieve the desired Coverage Probability. The method gives Prediction Intervals with appropriate coverage probabilities and small widths.",
      "year": "2023",
      "pages": "107597",
      "title": "Robust prediction interval estimation for Gaussian processes by cross-validation method",
      "number": "",
      "volume": "178",
      "authors": "Naoufal Acharki and Antoine Bertoncello and Josselin Garnier",
      "journal": "Computational Statistics & Data Analysis",
      "abstract": "Probabilistic regression models typically use the Maximum Likelihood Estimation or Cross-Validation to fit parameters. These methods can give an advantage to the solutions that fit observations on average, but they do not pay attention to the coverage and the width of Prediction Intervals. A robust two-step approach is used to address the problem of adjusting and calibrating Prediction Intervals for Gaussian Processes Regression. First, the covariance hyperparameters are determined by a standard Cross-Validation or Maximum Likelihood Estimation method. A Leave-One-Out Coverage Probability is introduced as a metric to adjust the covariance hyperparameters and assess the optimal type II Coverage Probability to a nominal level. Then a relaxation method is applied to choose the hyperparameters that minimize the Wasserstein distance between the Gaussian distribution with the initial hyperparameters (obtained by Cross-Validation or Maximum Likelihood Estimation) and the proposed Gaussian distribution with the hyperparameters that achieve the desired Coverage Probability. The method gives Prediction Intervals with appropriate coverage probabilities and small widths.",
      "bibtexId": "ACHARKI2023107597",
      "keywords": "Cross-validation, Coverage probability, Gaussian processes, Prediction intervals",
      "entryType": "article",
      "publisher": "",
      "categories": [
        "Other GP Litterature",
        "GP Hyperparameters"
      ],
      "citationKey": "ACHARKI2023107597",
      "originalBibTeX": "@article{ACHARKI2023107597, title = {Robust prediction interval estimation for Gaussian processes by cross-validation method}, journal = {Computational Statistics & Data Analysis}, volume = {178}, pages = {107597}, year = {2023}, issn = {0167-9473}, doi = {https://doi.org/10.1016/j.csda.2022.107597}, url = {https://www.sciencedirect.com/science/article/pii/S0167947322001773}, author = {Naoufal Acharki and Antoine Bertoncello and Josselin Garnier}, keywords = {Cross-validation, Coverage probability, Gaussian processes, Prediction intervals}, abstract = {Probabilistic regression models typically use the Maximum Likelihood Estimation or Cross-Validation to fit parameters. These methods can give an advantage to the solutions that fit observations on average, but they do not pay attention to the coverage and the width of Prediction Intervals. A robust two-step approach is used to address the problem of adjusting and calibrating Prediction Intervals for Gaussian Processes Regression. First, the covariance hyperparameters are determined by a standard Cross-Validation or Maximum Likelihood Estimation method. A Leave-One-Out Coverage Probability is introduced as a metric to adjust the covariance hyperparameters and assess the optimal type II Coverage Probability to a nominal level. Then a relaxation method is applied to choose the hyperparameters that minimize the Wasserstein distance between the Gaussian distribution with the initial hyperparameters (obtained by Cross-Validation or Maximum Likelihood Estimation) and the proposed Gaussian distribution with the hyperparameters that achieve the desired Coverage Probability. The method gives Prediction Intervals with appropriate coverage probabilities and small widths.} }"
    },
    {
      "id": 47,
      "doi": "",
      "pdf": "http://arxiv.org/pdf/1708.04738v1",
      "isbn": "",
      "issn": "",
      "link": "http://arxiv.org/abs/1708.04738v1",
      "note": "",
      "text": "",
      "year": "2017",
      "pages": "",
      "title": "Robust Gaussian Stochastic Process Emulation",
      "number": "",
      "volume": "",
      "authors": "Mengyang Gu, Xiaojing Wang, James O. Berger",
      "journal": "arXiv preprint",
      "abstract": "",
      "bibtexId": "guetal2017",
      "entryType": "article",
      "publisher": "",
      "categories": [
        "Other GP Litterature",
        "GP Hyperparameters"
      ]
    },
    {
      "id": 48,
      "doi": "10.1007/s10994-022-06172-1",
      "pdf": "",
      "isbn": "",
      "issn": "",
      "link": "https://doi.org/10.1007/s10994-022-06172-1",
      "note": "",
      "text": "",
      "year": "2022",
      "pages": "1821-1849",
      "title": "MAGMA: inference and prediction using multi-task Gaussian processes with common mean",
      "number": "",
      "volume": "111",
      "authors": "Arthur Leroy, Pierre Latouche, Benjamin Guedj, Servane Gey",
      "journal": "Machine Learning",
      "abstract": "",
      "bibtexId": "leroyetal2022",
      "entryType": "article",
      "publisher": "Springer Science and Business Media LLC",
      "categories": [
        "MO-GP",
        "Other GP Litterature"
      ]
    },
    {
      "id": 49,
      "doi": "",
      "pdf": "",
      "date": "2023-01-01",
      "isbn": "",
      "issn": "",
      "link": "http://jmlr.org/papers/v24/20-1321.html",
      "note": "",
      "text": "",
      "year": "2023",
      "pages": "1--49",
      "title": "Cluster-Specific Predictions with Multi-Task Gaussian Processes",
      "number": "5",
      "volume": "24",
      "authors": "Arthur Leroy and Pierre Latouche and Benjamin Guedj and Servane Gey",
      "journal": "Journal of Machine Learning Research",
      "abstract": "",
      "bibtexId": "JMLR:v24:20-1321",
      "entryType": "article",
      "publisher": "",
      "categories": [
        "MO-GP",
        "Other GP Litterature"
      ],
      "citationKey": "JMLR:v24:20-1321",
      "originalBibTeX": "@article{JMLR:v24:20-1321,   author  = {Arthur Leroy and Pierre Latouche and Benjamin Guedj and Servane Gey},   title   = {Cluster-Specific Predictions with Multi-Task Gaussian Processes},   journal = {Journal of Machine Learning Research},   year    = {2023},   volume  = {24},   number  = {5},   pages   = {1--49},   url     = {http://jmlr.org/papers/v24/20-1321.html} }"
    },
    {
      "id": 50,
      "doi": "",
      "pdf": "http://arxiv.org/pdf/2411.14679v4",
      "isbn": "",
      "issn": "",
      "link": "http://arxiv.org/abs/2411.14679v4",
      "note": "",
      "text": "",
      "year": "2024",
      "pages": "",
      "title": "Recursive Gaussian Process State Space Model",
      "number": "",
      "volume": "",
      "authors": "Tengjie Zheng, Haipeng Chen, Lin Cheng, Shengping Gong, Xu Huang",
      "journal": "arXiv preprint",
      "abstract": "",
      "bibtexId": "zhengetal2024",
      "entryType": "article",
      "publisher": "",
      "categories": [
        "Unsorted/unread"
      ]
    },
    {
      "x": 0,
      "y": -150,
      "id": 51,
      "doi": "",
      "pdf": "",
      "url": "http://www.theses.fr/2022IPPAX115/document",
      "date": "2022-01-01",
      "isbn": "",
      "issn": "",
      "link": "http://www.theses.fr/2022IPPAX115/document",
      "note": "",
      "text": "",
      "year": "2022",
      "month": "",
      "pages": "",
      "title": "Multi-fidelity surrogate modeling adapted to functional outputs for uncertainty quantification of complex models",
      "number": "",
      "school": "",
      "series": "",
      "volume": "",
      "address": "",
      "authors": "Kerleguer, Baptiste",
      "chapter": "",
      "edition": "",
      "journal": "",
      "abstract": "",
      "bibtexId": "kerleguer_multi-fidelity_2022",
      "keywords": "",
      "booktitle": "",
      "entryType": "phdthesis",
      "publisher": "",
      "categories": [
        "MF-GP",
        "MF-ARGP",
        "MF-GP TS"
      ],
      "citationKey": "kerleguer_multi-fidelity_2022",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@phdthesis{kerleguer_multi-fidelity_2022, \ttype = {{PhD} {Thesis}}, \ttitle = {Multi-fidelity surrogate modeling adapted to functional outputs for uncertainty quantification of complex models}, \turl = {http://www.theses.fr/2022IPPAX115/document}, \tauthor = {Kerleguer, Baptiste}, \tyear = {2022}, }"
    },
    {
      "x": 0,
      "y": -50,
      "id": 52,
      "doi": "10.48550/arXiv.1103.3817",
      "pdf": "",
      "url": "http://arxiv.org/abs/1103.3817",
      "date": "2011-01-01",
      "isbn": "",
      "issn": "",
      "link": "http://arxiv.org/abs/1103.3817",
      "note": "arXiv:1103.3817  version: 2",
      "text": "We introduce a novel geometric framework for separating the phase and the amplitude variability in functional data of the type frequently studied in growth curve analysis. This framework uses the Fisher-Rao Riemannian metric to derive a proper distance on the quotient space of functions modulo the time-warping group. A convenient square-root velocity function (SRVF) representation transforms the Fisher-Rao metric into the standard \\${\\textbackslash}ltwo\\$ metric, simplifying the computations. This distance is then used to define a Karcher mean template and warp the individual functions to align them with the Karcher mean template. The strength of this framework is demonstrated by deriving a consistent estimator of a signal observed under random warping, scaling, and vertical translation. These ideas are demonstrated using both simulated and real data from different application domains: the Berkeley growth study, handwritten signature curves, neuroscience spike trains, and gene expression signals. The proposed method is empirically shown to be be superior in performance to several recently published methods for functional alignment.",
      "year": "2011",
      "month": "",
      "pages": "",
      "title": "Registration of {Functional} {Data} {Using} {Fisher}-{Rao} {Metric}",
      "number": "",
      "school": "",
      "series": "",
      "volume": "",
      "address": "",
      "authors": "Srivastava, Anuj and Wu, Wei and Kurtek, Sebastian and Klassen, Eric and Marron, J. S.",
      "chapter": "",
      "edition": "",
      "journal": "",
      "abstract": "We introduce a novel geometric framework for separating the phase and the amplitude variability in functional data of the type frequently studied in growth curve analysis. This framework uses the Fisher-Rao Riemannian metric to derive a proper distance on the quotient space of functions modulo the time-warping group. A convenient square-root velocity function (SRVF) representation transforms the Fisher-Rao metric into the standard \\${\\textbackslash}ltwo\\$ metric, simplifying the computations. This distance is then used to define a Karcher mean template and warp the individual functions to align them with the Karcher mean template. The strength of this framework is demonstrated by deriving a consistent estimator of a signal observed under random warping, scaling, and vertical translation. These ideas are demonstrated using both simulated and real data from different application domains: the Berkeley growth study, handwritten signature curves, neuroscience spike trains, and gene expression signals. The proposed method is empirically shown to be be superior in performance to several recently published methods for functional alignment.",
      "bibtexId": "srivastava_registration_2011",
      "keywords": "Mathematics - Statistics Theory, Statistics - Applications, Statistics - Methodology",
      "booktitle": "",
      "entryType": "misc",
      "publisher": "arXiv",
      "categories": [
        "Model calibration"
      ],
      "citationKey": "srivastava_registration_2011",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@misc{srivastava_registration_2011, \ttitle = {Registration of {Functional} {Data} {Using} {Fisher}-{Rao} {Metric}}, \turl = {http://arxiv.org/abs/1103.3817}, \tdoi = {10.48550/arXiv.1103.3817}, \tabstract = {We introduce a novel geometric framework for separating the phase and the amplitude variability in functional data of the type frequently studied in growth curve analysis. This framework uses the Fisher-Rao Riemannian metric to derive a proper distance on the quotient space of functions modulo the time-warping group. A convenient square-root velocity function (SRVF) representation transforms the Fisher-Rao metric into the standard \\${\\textbackslash}ltwo\\$ metric, simplifying the computations. This distance is then used to define a Karcher mean template and warp the individual functions to align them with the Karcher mean template. The strength of this framework is demonstrated by deriving a consistent estimator of a signal observed under random warping, scaling, and vertical translation. These ideas are demonstrated using both simulated and real data from different application domains: the Berkeley growth study, handwritten signature curves, neuroscience spike trains, and gene expression signals. The proposed method is empirically shown to be be superior in performance to several recently published methods for functional alignment.}, \turldate = {2025-11-18}, \tpublisher = {arXiv}, \tauthor = {Srivastava, Anuj and Wu, Wei and Kurtek, Sebastian and Klassen, Eric and Marron, J. S.}, \tmonth = may, \tyear = {2011}, \tnote = {arXiv:1103.3817  version: 2}, \tkeywords = {Mathematics - Statistics Theory, Statistics - Applications, Statistics - Methodology}, }"
    },
    {
      "x": 0,
      "y": 50,
      "id": 53,
      "doi": "10.48550/arXiv.2105.08604",
      "pdf": "",
      "url": "http://arxiv.org/abs/2105.08604",
      "date": "2021-01-01",
      "isbn": "",
      "issn": "",
      "link": "http://arxiv.org/abs/2105.08604",
      "note": "arXiv:2105.08604",
      "text": "Elastic Riemannian metrics have been used successfully in the past for statistical treatments of functional and curve shape data. However, this usage has suffered from an important restriction: the function boundaries are assumed fixed and matched. Functional data exhibiting unmatched boundaries typically arise from dynamical systems with variable evolution rates such as COVID-19 infection rate curves associated with different geographical regions. In this case, it is more natural to model such data with sliding boundaries and use partial matching, i.e., only a part of a function is matched to another function. Here, we develop a comprehensive Riemannian framework that allows for partial matching, comparing, and clustering of functions under both phase variability and uncertain boundaries. We extend past work by: (1) Forming a joint action of the time-warping and time-scaling groups; (2) Introducing a metric that is invariant to this joint action, allowing for a gradient-based approach to elastic partial matching; and (3) Presenting a modification that, while losing the metric property, allows one to control relative influence of the two groups. This framework is illustrated for registering and clustering shapes of COVID-19 rate curves, identifying essential patterns, minimizing mismatch errors, and reducing variability within clusters compared to previous methods.",
      "year": "2021",
      "month": "",
      "pages": "",
      "title": "Shape {Analysis} of {Functional} {Data} with {Elastic} {Partial} {Matching}",
      "number": "",
      "school": "",
      "series": "",
      "volume": "",
      "address": "",
      "authors": "Bryner, Darshan and Srivastava, Anuj",
      "chapter": "",
      "edition": "",
      "journal": "",
      "abstract": "Elastic Riemannian metrics have been used successfully in the past for statistical treatments of functional and curve shape data. However, this usage has suffered from an important restriction: the function boundaries are assumed fixed and matched. Functional data exhibiting unmatched boundaries typically arise from dynamical systems with variable evolution rates such as COVID-19 infection rate curves associated with different geographical regions. In this case, it is more natural to model such data with sliding boundaries and use partial matching, i.e., only a part of a function is matched to another function. Here, we develop a comprehensive Riemannian framework that allows for partial matching, comparing, and clustering of functions under both phase variability and uncertain boundaries. We extend past work by: (1) Forming a joint action of the time-warping and time-scaling groups; (2) Introducing a metric that is invariant to this joint action, allowing for a gradient-based approach to elastic partial matching; and (3) Presenting a modification that, while losing the metric property, allows one to control relative influence of the two groups. This framework is illustrated for registering and clustering shapes of COVID-19 rate curves, identifying essential patterns, minimizing mismatch errors, and reducing variability within clusters compared to previous methods.",
      "bibtexId": "bryner_shape_2021",
      "keywords": "Computer Science - Computer Vision and Pattern Recognition, Statistics - Methodology",
      "booktitle": "",
      "entryType": "misc",
      "publisher": "arXiv",
      "categories": [
        "Model calibration"
      ],
      "citationKey": "bryner_shape_2021",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@misc{bryner_shape_2021, \ttitle = {Shape {Analysis} of {Functional} {Data} with {Elastic} {Partial} {Matching}}, \turl = {http://arxiv.org/abs/2105.08604}, \tdoi = {10.48550/arXiv.2105.08604}, \tabstract = {Elastic Riemannian metrics have been used successfully in the past for statistical treatments of functional and curve shape data. However, this usage has suffered from an important restriction: the function boundaries are assumed fixed and matched. Functional data exhibiting unmatched boundaries typically arise from dynamical systems with variable evolution rates such as COVID-19 infection rate curves associated with different geographical regions. In this case, it is more natural to model such data with sliding boundaries and use partial matching, i.e., only a part of a function is matched to another function. Here, we develop a comprehensive Riemannian framework that allows for partial matching, comparing, and clustering of functions under both phase variability and uncertain boundaries. We extend past work by: (1) Forming a joint action of the time-warping and time-scaling groups; (2) Introducing a metric that is invariant to this joint action, allowing for a gradient-based approach to elastic partial matching; and (3) Presenting a modification that, while losing the metric property, allows one to control relative influence of the two groups. This framework is illustrated for registering and clustering shapes of COVID-19 rate curves, identifying essential patterns, minimizing mismatch errors, and reducing variability within clusters compared to previous methods.}, \turldate = {2025-11-17}, \tpublisher = {arXiv}, \tauthor = {Bryner, Darshan and Srivastava, Anuj}, \tmonth = may, \tyear = {2021}, \tnote = {arXiv:2105.08604}, \tkeywords = {Computer Science - Computer Vision and Pattern Recognition, Statistics - Methodology}, }"
    },
    {
      "x": 0,
      "y": 150,
      "id": 54,
      "doi": "10.1137/24M1644092",
      "pdf": "",
      "url": "https://epubs.siam.org/doi/10.1137/24M1644092",
      "date": "2025-01-01",
      "isbn": "",
      "issn": "2166-2525",
      "link": "https://epubs.siam.org/doi/10.1137/24M1644092",
      "note": "",
      "text": "",
      "year": "2025",
      "month": "",
      "pages": "195--227",
      "title": "Elastic {Bayesian} {Model} {Calibration}",
      "number": "1",
      "school": "",
      "series": "",
      "volume": "13",
      "address": "",
      "authors": "Francom, Devin and Tucker, J. Derek and Huerta, Gabriel and Shuler, Kurtis and Ries, Daniel",
      "chapter": "",
      "edition": "",
      "journal": "SIAM/ASA Journal on Uncertainty Quantification",
      "abstract": "",
      "bibtexId": "francom_elastic_2025",
      "keywords": "",
      "booktitle": "",
      "entryType": "article",
      "publisher": "",
      "categories": [
        "Model calibration"
      ],
      "citationKey": "francom_elastic_2025",
      "institution": "",
      "howpublished": "",
      "organization": "",
      "originalBibTeX": "@article{francom_elastic_2025, \ttitle = {Elastic {Bayesian} {Model} {Calibration}}, \tvolume = {13}, \tissn = {2166-2525}, \turl = {https://epubs.siam.org/doi/10.1137/24M1644092}, \tdoi = {10.1137/24M1644092}, \tlanguage = {en}, \tnumber = {1}, \turldate = {2025-11-17}, \tjournal = {SIAM/ASA Journal on Uncertainty Quantification}, \tauthor = {Francom, Devin and Tucker, J. Derek and Huerta, Gabriel and Shuler, Kurtis and Ries, Daniel}, \tmonth = mar, \tyear = {2025}, \tpages = {195--227}, }"
    }
  ],
  "zones": [
    {
      "x": -753.0879641734508,
      "y": -254.3306998514341,
      "tag": "Application MF-GP",
      "color": "#e74c3c",
      "width": 577.9635614172787,
      "height": 360.3977973031349
    },
    {
      "x": -789.4885533907742,
      "y": 219.30852428177508,
      "tag": "MF-GP TS",
      "color": "#e74c3c",
      "width": 195.9315536284053,
      "height": 222.59102507697725
    },
    {
      "x": -544.4805894012387,
      "y": 180.27581584247122,
      "tag": "MF-DGP",
      "color": "#f1c40f",
      "width": 361.6869894693558,
      "height": 402.2296756870868
    },
    {
      "x": -973.2081978112524,
      "y": 181.11743779816933,
      "tag": "MF-ARGP",
      "color": "#2ecc71",
      "width": 412.69133554731167,
      "height": 403.42605228555783
    },
    {
      "x": -1210.0085652762243,
      "y": 181.90501536515544,
      "tag": "MF-NARGP",
      "color": "#3498db",
      "width": 220.9054217712237,
      "height": 403.9533727221584
    },
    {
      "x": -1234.4093495255165,
      "y": -274.50551351128,
      "tag": "MF-GP",
      "color": "#9b59b6",
      "width": 1086.611220442218,
      "height": 887.13996591213
    },
    {
      "x": -968.1319619148255,
      "y": -681.2216904107522,
      "tag": "MO-MF-GP",
      "color": "#9c3a87",
      "width": 393.2134007585335,
      "height": 308.01694058154237
    },
    {
      "x": -105.09152161517166,
      "y": -282.24214247737984,
      "tag": "Other GP Litterature",
      "color": "#e74c3c",
      "width": 1126.4205544425652,
      "height": 893.5015977137855
    },
    {
      "x": -1206.4321521357165,
      "y": -208.96603503359907,
      "tag": "Other MF-GP",
      "color": "#1abc9c",
      "width": 410.00568832731756,
      "height": 275.73661111239176
    },
    {
      "x": -1206.0808927458836,
      "y": -645.1872590141304,
      "tag": "POD",
      "color": "#f39c12",
      "width": 200,
      "height": 200
    },
    {
      "x": -1238.1055266073242,
      "y": -726.8128556364745,
      "tag": "Unsorted/unread",
      "color": "#e9edf1",
      "width": 707.3633527737742,
      "height": 412.2755747408009
    },
    {
      "x": -337.1145565867241,
      "y": -193.529404035289,
      "tag": "BO-GP",
      "color": "#2e9e4a",
      "width": 523.5634531196451,
      "height": 255.6202278642723
    },
    {
      "x": 73.34048990821091,
      "y": 143.26465788413498,
      "tag": "GP Hyperparameters",
      "color": "#2e73c2",
      "width": 344.15130574266755,
      "height": 439.7377127241317
    },
    {
      "x": 461.7975129725076,
      "y": -252.0427365545292,
      "tag": "MO-GP",
      "color": "#3498db",
      "width": 212.08107060833538,
      "height": 289.9649527810864
    },
    {
      "x": -103.49268867583646,
      "y": -597.6433737730702,
      "tag": "Model calibration",
      "color": "#1abc9c",
      "width": 276.124424925507,
      "height": 282.08394488792806
    }
  ],
  "positions": {
    "1": {
      "x": 334,
      "y": -109
    },
    "2": {
      "x": -278,
      "y": 272
    },
    "3": {
      "x": -27,
      "y": 390
    },
    "4": {
      "x": -264,
      "y": -20
    },
    "5": {
      "x": -18,
      "y": 691
    },
    "6": {
      "x": -25,
      "y": 559
    },
    "7": {
      "x": -1125,
      "y": -559
    },
    "8": {
      "x": -29,
      "y": 498
    },
    "9": {
      "x": -872,
      "y": -468
    },
    "10": {
      "x": -690,
      "y": 319
    },
    "11": {
      "x": -724,
      "y": -470
    },
    "12": {
      "x": -1133,
      "y": 272
    },
    "13": {
      "x": -26,
      "y": -60
    },
    "14": {
      "x": -714,
      "y": -581
    },
    "15": {
      "x": 568,
      "y": -10
    },
    "16": {
      "x": -875,
      "y": -26
    },
    "17": {
      "x": -1138,
      "y": -106
    },
    "19": {
      "x": -26,
      "y": 1
    },
    "20": {
      "x": -1019,
      "y": 24
    },
    "21": {
      "x": -463,
      "y": 319
    },
    "22": {
      "x": -1136,
      "y": 539
    },
    "23": {
      "x": -659,
      "y": -159
    },
    "25": {
      "x": -1119,
      "y": -499
    },
    "26": {
      "x": 336,
      "y": -203
    },
    "27": {
      "x": -873,
      "y": 532
    },
    "28": {
      "x": -27,
      "y": 335
    },
    "29": {
      "x": -627,
      "y": 25
    },
    "30": {
      "x": -452,
      "y": 36
    },
    "31": {
      "x": -874,
      "y": 320
    },
    "32": {
      "x": 97,
      "y": -123
    },
    "33": {
      "x": -33,
      "y": -124
    },
    "34": {
      "x": -1121,
      "y": -48
    },
    "35": {
      "x": -876,
      "y": -106
    },
    "36": {
      "x": -430,
      "y": 499
    },
    "37": {
      "x": -490,
      "y": -91
    },
    "38": {
      "x": 179,
      "y": 235
    },
    "39": {
      "x": 141,
      "y": 320
    },
    "40": {
      "x": 341,
      "y": 283
    },
    "44": {
      "x": 177,
      "y": 438
    },
    "45": {
      "x": -874,
      "y": 434
    },
    "46": {
      "x": 300,
      "y": 368
    },
    "47": {
      "x": 307,
      "y": 497
    },
    "48": {
      "x": 567,
      "y": -86
    },
    "49": {
      "x": 563,
      "y": -158
    },
    "50": {
      "x": -1087,
      "y": -400
    },
    "51": {
      "x": -693,
      "y": 397
    },
    "52": {
      "x": -6,
      "y": -360
    },
    "53": {
      "x": -6,
      "y": -441
    },
    "54": {
      "x": -7,
      "y": -506
    }
  },
  "previewImage": "data:image/png;base64,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"
}